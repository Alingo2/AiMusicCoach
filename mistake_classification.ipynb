{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/wrong_train.json\")\n",
    "obj_r2 = open(\"./test/json/wrong_train_type.json\")\n",
    "input_train = json.load(obj_r)\n",
    "input_train = np.array(input_train)\n",
    "print(len(input_train))\n",
    "y = json.load(obj_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.zeros((len(y),5))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    index = y[i]\n",
    "    y_train[i] = 1\n",
    "    \n",
    "x_val=input_train[0:20]\n",
    "y_val=y_train[0:20]\n",
    "input_train=input_train[20:]\n",
    "y_train=y_train[20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/400\n",
      "60/60 [==============================] - 0s 7ms/step - loss: 8.0487 - acc: 0.1333 - val_loss: 8.0474 - val_acc: 0.0500\n",
      "Epoch 2/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0473 - acc: 0.1333 - val_loss: 8.0473 - val_acc: 0.0000e+00\n",
      "Epoch 3/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0667 - val_loss: 8.0472 - val_acc: 0.1500\n",
      "Epoch 4/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.1167 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 5/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 6/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.3167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 7/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 8/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 9/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 10/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.3167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 11/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 12/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 13/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 14/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 15/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 16/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 17/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 18/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 19/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 20/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 21/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 22/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 23/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 24/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 25/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 26/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 27/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 28/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 29/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 30/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 31/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 32/400\n",
      "60/60 [==============================] - 0s 415us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 33/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 34/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 35/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 36/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 37/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 38/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 39/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 40/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 41/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 42/400\n",
      "60/60 [==============================] - 0s 382us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 43/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 44/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 45/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 46/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 47/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 48/400\n",
      "60/60 [==============================] - 0s 765us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 49/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 50/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 51/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 52/400\n",
      "60/60 [==============================] - 0s 764us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 53/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 54/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 55/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 56/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 57/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 58/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 59/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 60/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 61/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 62/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 63/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 64/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 65/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 66/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 67/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 68/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 69/400\n",
      "60/60 [==============================] - 0s 398us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 70/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 71/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 72/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 73/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 74/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 75/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 76/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 77/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 78/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 79/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 80/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 81/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 82/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 83/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 84/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 85/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 86/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 87/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 88/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 89/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 90/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 91/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 92/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 93/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 94/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 95/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 96/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 97/400\n",
      "60/60 [==============================] - 0s 415us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 98/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 99/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 100/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 101/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 102/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 103/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 104/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 105/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 106/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 107/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 108/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 109/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 110/400\n",
      "60/60 [==============================] - 0s 382us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 111/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 112/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 113/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 114/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 115/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 116/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 117/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 118/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 119/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 121/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 122/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 123/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 124/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 125/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 126/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 127/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 128/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 129/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 130/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 131/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 132/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 133/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 134/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 135/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 136/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 137/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 138/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 139/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 140/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 141/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 142/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 143/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 144/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.5000 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 145/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 146/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 147/400\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.0472 - acc: 1.000 - 0s 582us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 148/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 149/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.5000 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 150/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 151/400\n",
      "60/60 [==============================] - 0s 781us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 152/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 153/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 154/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 155/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 156/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 157/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 158/400\n",
      "60/60 [==============================] - 0s 533us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 159/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 160/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 161/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 162/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 163/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 164/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 165/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 166/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 167/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 168/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 169/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 170/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 171/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 172/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 173/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 174/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 175/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 176/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 177/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 178/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.5000 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 179/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 180/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 181/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 182/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 183/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 184/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 185/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 186/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 187/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 188/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 189/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 190/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 191/400\n",
      "60/60 [==============================] - 0s 516us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 192/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 193/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 194/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 195/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 196/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 197/400\n",
      "60/60 [==============================] - 0s 332us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 198/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 199/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 200/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 201/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 202/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 203/400\n",
      "60/60 [==============================] - 0s 365us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 204/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 205/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 206/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 207/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 208/400\n",
      "60/60 [==============================] - 0s 581us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 209/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.5000 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 210/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 211/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 212/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 213/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 214/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 215/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 216/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 217/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 218/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 219/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 220/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 221/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 222/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 223/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 224/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 225/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 226/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 227/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 228/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 229/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 230/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 231/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 232/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 233/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 234/400\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.0472 - acc: 0.0000e+0 - 0s 598us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 235/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 236/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 237/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 238/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 631us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 239/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 240/400\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.0472 - acc: 0.0000e+0 - 0s 382us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 241/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 242/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 243/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 244/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 245/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 246/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 247/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 248/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 249/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 250/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 251/400\n",
      "60/60 [==============================] - 0s 332us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 252/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 253/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 254/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 255/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 256/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 257/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 258/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 259/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 260/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 261/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 262/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 263/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 264/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 265/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 266/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 267/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 268/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 269/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 270/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 271/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 272/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 273/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 274/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 275/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 276/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 277/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 278/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 279/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 280/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 281/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 282/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 283/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 284/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 285/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 286/400\n",
      "60/60 [==============================] - 0s 581us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 287/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 288/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 289/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 290/400\n",
      "60/60 [==============================] - 0s 382us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 291/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 292/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 293/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 294/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 295/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 296/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 297/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 298/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 299/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 300/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 301/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 302/400\n",
      "60/60 [==============================] - 0s 498us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 303/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 304/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 305/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 306/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 307/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 308/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 309/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 310/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 311/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 312/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 313/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 314/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 315/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 316/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 317/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 318/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 319/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 320/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 321/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 322/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 323/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 324/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 325/400\n",
      "60/60 [==============================] - 0s 415us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 326/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 327/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 328/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 329/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 330/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 331/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 332/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 333/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 334/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 335/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 336/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 337/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 338/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 339/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 340/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 341/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 342/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 343/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 344/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 345/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 346/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 347/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 348/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 349/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 350/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 351/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 352/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 353/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 354/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 355/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 356/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 357/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 358/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 359/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 360/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 361/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 362/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 363/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 364/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 365/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 366/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 367/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 368/400\n",
      "60/60 [==============================] - 0s 765us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 369/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 370/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 371/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 372/400\n",
      "60/60 [==============================] - 0s 366us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 373/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 374/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 375/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 376/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 377/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 378/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 379/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 380/400\n",
      "60/60 [==============================] - 0s 964us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 381/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 382/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 383/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 384/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 385/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 386/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 387/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 388/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 389/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 390/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 391/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 392/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 393/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 394/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 395/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 396/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 397/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 398/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 399/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n",
      "Epoch 400/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(input_train,y_train,batch_size=5,epochs=400,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/wrong_test.json\")\n",
    "obj_r2 = open(\"./test/json/wrong_test_type.json\")\n",
    "\n",
    "\n",
    "test = json.load(obj_r)\n",
    "test = np.array(test)\n",
    "t = json.load(obj_r2)\n",
    "print(len(test))\n",
    "t = np.array(t)\n",
    "test_standard = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测概率 [0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20013693, 0.20338574, 0.20019384, 0.20013693, 0.20013693, 0.20013693, 0.20013693]\n",
      "预测概率不为1个数： 0\n",
      "总量： 20 错误量： 14\n",
      "正确率： 0.3\n"
     ]
    }
   ],
   "source": [
    "wrongfile_list=[]\n",
    "predict = model.predict(test)\n",
    "predict_type = []\n",
    "predict_proba = []\n",
    "preict_not_1 = 0\n",
    "for i in range(len(predict)):\n",
    "    index = np.argmax(predict[i])\n",
    "    predict_proba.append(predict[i][index]) \n",
    "    predict_type.append(index)\n",
    "\n",
    "print(\"预测概率\",predict_proba)\n",
    "print(\"预测概率不为1个数：\",preict_not_1)\n",
    "num = 0\n",
    "wrong_num = 0\n",
    "for i in range(len(predict_type)):\n",
    "    if abs(predict_type[i] - test_standard[i])==0:\n",
    "        num += 1\n",
    "    else:\n",
    "        wrong_num += 1\n",
    "accuracy = num/len(predict_type)\n",
    "# print(predict_note)\n",
    "# print(test_standard)\n",
    "print(\"总量：\",len(predict_type),\"错误量：\",wrong_num)\n",
    "print(\"正确率：\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "print(history_dict.keys())\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
