{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dense(45,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/datasetx_train2.json\")\n",
    "obj_r2 = open(\"./test/json/datasetx_result2.json\")\n",
    "input_train = json.load(obj_r)\n",
    "input_train = np.array(input_train)\n",
    "print(len(input_train))\n",
    "y = json.load(obj_r2)\n",
    "y = np.array(y)\n",
    "y = y*2093.004\n",
    "\n",
    "obj_r=open(\"./test/json/datasetx_train1.json\")\n",
    "obj_r2 = open(\"./test/json/datasetx_result1.json\")\n",
    "test = json.load(obj_r)\n",
    "test = np.array(test)\n",
    "t = json.load(obj_r2)\n",
    "print(len(test))\n",
    "t = np.array(t)\n",
    "t = t*2093.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fre_to_note_piano(fre):\n",
    "    index = round(math.log(fre / 27.5,2**(1/12)))\n",
    "    dict = [\"A1 \",\"#A1 \",\"B1 \",\"C2 \",\"#C2 \",\"D2 \",\"#D2 \",\"E2 \",\"F2 \",\"#F2 \",\"G2 \",\"#G2 \",\"A2 \",\"#A2 \",\"B2 \",\"C3 \",\"#C3 \",\"D3 \",\"#D3 \",\"E3 \",\"F3 \",\"#F3 \",\"G3 \",\"#G3 \",\"A3 \",\"#A3 \",\"B3 \",\"C4 \",\"#C4 \",\"D4 \",\"#D4 \",\"E4 \",\"F4 \",\"#F4 \",\"G4 \",\"#G4 \",\"A4 \", \"#A4 \", \"B4 \", \"C5 \", \"#C5 \", \"D5 \", \"#D5 \", \"E5 \",\"F5 \",\"#F5 \",\"G5 \",\"#G5 \",\"A5 \", \"#A5 \", \"B5 \", \"C6 \", \"#C6 \", \"D6 \", \"#D6 \", \"E6 \",\n",
    "    \"F6 \",\"#F6 \",\"G6 \",\"#G6 \",\"A6 \", \"#A6 \", \"B6 \", \"C7 \", \"#C7 \", \"D7 \", \"#D7 \", \"E7 \",\"F7 \",\"#F7 \",\"G7 \",\"#G7 \",\"A7 \", \"#A7 \", \"B7 \", \"C8 \",\"#C8 \",\"D8 \",\"#D8 \",\"E8 \",\"F8 \",\"#F8 \",\"G8 \",\"#G8 \",\"A8 \",\"#A8 \",\"B8 \",\"C9 \",\"#C9 \", \"D9 \", \"#D9 \", \"E9 \",\"F9 \",\"#F9 \",\"G9 \",\"#G9 \",\"A9 \", \"#A9 \", \"B9 \", \"C10 \"]\n",
    "    return index+21\n",
    "y_train = np.zeros((len(y),45))\n",
    "test_standard = []\n",
    "for i in range(len(y)):\n",
    "    index = fre_to_note_piano(y[i])\n",
    "    y_train[i][index-40] = 1\n",
    "\n",
    "for j in range(len(t)):\n",
    "    index = fre_to_note_piano(t[j])\n",
    "    test_standard.append(index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\MyCode\\Anaconda\\envs\\AiMusic\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/300\n",
      "756/756 [==============================] - 2s 3ms/step - loss: 3.6327 - acc: 0.1812\n",
      "Epoch 2/300\n",
      "756/756 [==============================] - 0s 588us/step - loss: 2.5630 - acc: 0.4788\n",
      "Epoch 3/300\n",
      "756/756 [==============================] - 0s 588us/step - loss: 1.3306 - acc: 0.7513\n",
      "Epoch 4/300\n",
      "756/756 [==============================] - 0s 575us/step - loss: 0.6652 - acc: 0.8968\n",
      "Epoch 5/300\n",
      "756/756 [==============================] - 0s 602us/step - loss: 0.4264 - acc: 0.9127\n",
      "Epoch 6/300\n",
      "756/756 [==============================] - 0s 538us/step - loss: 0.3017 - acc: 0.9444\n",
      "Epoch 7/300\n",
      "756/756 [==============================] - 0s 549us/step - loss: 0.2477 - acc: 0.9444\n",
      "Epoch 8/300\n",
      "756/756 [==============================] - 0s 604us/step - loss: 0.2027 - acc: 0.9563\n",
      "Epoch 9/300\n",
      "756/756 [==============================] - 1s 684us/step - loss: 0.1860 - acc: 0.9563\n",
      "Epoch 10/300\n",
      "756/756 [==============================] - 1s 714us/step - loss: 0.1778 - acc: 0.9630\n",
      "Epoch 11/300\n",
      "756/756 [==============================] - 1s 757us/step - loss: 0.1656 - acc: 0.9656\n",
      "Epoch 12/300\n",
      "756/756 [==============================] - 0s 643us/step - loss: 0.1490 - acc: 0.9656\n",
      "Epoch 13/300\n",
      "756/756 [==============================] - 0s 640us/step - loss: 0.1375 - acc: 0.9669\n",
      "Epoch 14/300\n",
      "756/756 [==============================] - 0s 602us/step - loss: 0.1346 - acc: 0.9762\n",
      "Epoch 15/300\n",
      "756/756 [==============================] - 0s 599us/step - loss: 0.1247 - acc: 0.9735\n",
      "Epoch 16/300\n",
      "756/756 [==============================] - 0s 591us/step - loss: 0.1173 - acc: 0.9722\n",
      "Epoch 17/300\n",
      "756/756 [==============================] - 1s 803us/step - loss: 0.1110 - acc: 0.9815\n",
      "Epoch 18/300\n",
      "756/756 [==============================] - 0s 654us/step - loss: 0.1030 - acc: 0.9775\n",
      "Epoch 19/300\n",
      "756/756 [==============================] - 1s 668us/step - loss: 0.0920 - acc: 0.9802\n",
      "Epoch 20/300\n",
      "756/756 [==============================] - 1s 703us/step - loss: 0.0942 - acc: 0.9815\n",
      "Epoch 21/300\n",
      "756/756 [==============================] - 1s 673us/step - loss: 0.1066 - acc: 0.9775\n",
      "Epoch 22/300\n",
      "756/756 [==============================] - 1s 737us/step - loss: 0.0728 - acc: 0.9854\n",
      "Epoch 23/300\n",
      "756/756 [==============================] - 1s 683us/step - loss: 0.0793 - acc: 0.9854\n",
      "Epoch 24/300\n",
      "756/756 [==============================] - 1s 673us/step - loss: 0.0901 - acc: 0.9828\n",
      "Epoch 25/300\n",
      "756/756 [==============================] - 0s 604us/step - loss: 0.0755 - acc: 0.9841\n",
      "Epoch 26/300\n",
      "756/756 [==============================] - 0s 590us/step - loss: 0.0695 - acc: 0.9894\n",
      "Epoch 27/300\n",
      "756/756 [==============================] - 0s 576us/step - loss: 0.0701 - acc: 0.9881\n",
      "Epoch 28/300\n",
      "756/756 [==============================] - 0s 548us/step - loss: 0.0782 - acc: 0.9868\n",
      "Epoch 29/300\n",
      "756/756 [==============================] - 0s 580us/step - loss: 0.0702 - acc: 0.9841\n",
      "Epoch 30/300\n",
      "756/756 [==============================] - 0s 570us/step - loss: 0.0683 - acc: 0.9907\n",
      "Epoch 31/300\n",
      "756/756 [==============================] - 0s 574us/step - loss: 0.0652 - acc: 0.9868\n",
      "Epoch 32/300\n",
      "756/756 [==============================] - 0s 596us/step - loss: 0.0668 - acc: 0.9894\n",
      "Epoch 33/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0749 - acc: 0.9894\n",
      "Epoch 34/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0626 - acc: 0.9894\n",
      "Epoch 35/300\n",
      "756/756 [==============================] - 0s 575us/step - loss: 0.0615 - acc: 0.9921\n",
      "Epoch 36/300\n",
      "756/756 [==============================] - 0s 582us/step - loss: 0.0640 - acc: 0.9907\n",
      "Epoch 37/300\n",
      "756/756 [==============================] - 0s 607us/step - loss: 0.0550 - acc: 0.9921\n",
      "Epoch 38/300\n",
      "756/756 [==============================] - 0s 596us/step - loss: 0.0632 - acc: 0.9907\n",
      "Epoch 39/300\n",
      "756/756 [==============================] - 0s 588us/step - loss: 0.0585 - acc: 0.9894\n",
      "Epoch 40/300\n",
      "756/756 [==============================] - 0s 571us/step - loss: 0.0565 - acc: 0.9921\n",
      "Epoch 41/300\n",
      "756/756 [==============================] - 0s 580us/step - loss: 0.0539 - acc: 0.9947\n",
      "Epoch 42/300\n",
      "756/756 [==============================] - 0s 540us/step - loss: 0.0557 - acc: 0.9947\n",
      "Epoch 43/300\n",
      "756/756 [==============================] - 0s 588us/step - loss: 0.0519 - acc: 0.9960\n",
      "Epoch 44/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0572 - acc: 0.9921\n",
      "Epoch 45/300\n",
      "756/756 [==============================] - 0s 576us/step - loss: 0.0531 - acc: 0.9947\n",
      "Epoch 46/300\n",
      "756/756 [==============================] - 0s 576us/step - loss: 0.0525 - acc: 0.9947\n",
      "Epoch 47/300\n",
      "756/756 [==============================] - 0s 571us/step - loss: 0.0556 - acc: 0.9947\n",
      "Epoch 48/300\n",
      "756/756 [==============================] - 0s 605us/step - loss: 0.0549 - acc: 0.9947\n",
      "Epoch 49/300\n",
      "756/756 [==============================] - 0s 619us/step - loss: 0.0537 - acc: 0.9947\n",
      "Epoch 50/300\n",
      "756/756 [==============================] - 0s 577us/step - loss: 0.0512 - acc: 0.9960\n",
      "Epoch 51/300\n",
      "756/756 [==============================] - 0s 563us/step - loss: 0.0538 - acc: 0.9947\n",
      "Epoch 52/300\n",
      "756/756 [==============================] - 0s 568us/step - loss: 0.0555 - acc: 0.9947\n",
      "Epoch 53/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0470 - acc: 0.9960\n",
      "Epoch 54/300\n",
      "756/756 [==============================] - 0s 525us/step - loss: 0.0522 - acc: 0.9934\n",
      "Epoch 55/300\n",
      "756/756 [==============================] - 0s 630us/step - loss: 0.0520 - acc: 0.9960\n",
      "Epoch 56/300\n",
      "756/756 [==============================] - 0s 608us/step - loss: 0.0482 - acc: 0.9960\n",
      "Epoch 57/300\n",
      "756/756 [==============================] - 0s 646us/step - loss: 0.0549 - acc: 0.9947\n",
      "Epoch 58/300\n",
      "756/756 [==============================] - 0s 657us/step - loss: 0.0496 - acc: 0.9960\n",
      "Epoch 59/300\n",
      "756/756 [==============================] - 0s 606us/step - loss: 0.0518 - acc: 0.9960\n",
      "Epoch 60/300\n",
      "756/756 [==============================] - 0s 635us/step - loss: 0.0495 - acc: 0.9960\n",
      "Epoch 61/300\n",
      "756/756 [==============================] - 0s 643us/step - loss: 0.0503 - acc: 0.9960\n",
      "Epoch 62/300\n",
      "756/756 [==============================] - 0s 644us/step - loss: 0.0500 - acc: 0.9960\n",
      "Epoch 63/300\n",
      "756/756 [==============================] - 0s 619us/step - loss: 0.0498 - acc: 0.9960\n",
      "Epoch 64/300\n",
      "756/756 [==============================] - 0s 646us/step - loss: 0.0464 - acc: 0.9960\n",
      "Epoch 65/300\n",
      "756/756 [==============================] - 0s 602us/step - loss: 0.0484 - acc: 0.9947\n",
      "Epoch 66/300\n",
      "756/756 [==============================] - 0s 600us/step - loss: 0.0480 - acc: 0.9960\n",
      "Epoch 67/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0470 - acc: 0.9960\n",
      "Epoch 68/300\n",
      "756/756 [==============================] - 0s 571us/step - loss: 0.0468 - acc: 0.9960\n",
      "Epoch 69/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0473 - acc: 0.9960\n",
      "Epoch 70/300\n",
      "756/756 [==============================] - 0s 574us/step - loss: 0.0491 - acc: 0.9960\n",
      "Epoch 71/300\n",
      "756/756 [==============================] - 0s 576us/step - loss: 0.0472 - acc: 0.9960\n",
      "Epoch 72/300\n",
      "756/756 [==============================] - 0s 576us/step - loss: 0.0453 - acc: 0.9960\n",
      "Epoch 73/300\n",
      "756/756 [==============================] - 0s 580us/step - loss: 0.0481 - acc: 0.9960\n",
      "Epoch 74/300\n",
      "756/756 [==============================] - 0s 588us/step - loss: 0.0474 - acc: 0.9960\n",
      "Epoch 75/300\n",
      "756/756 [==============================] - 0s 579us/step - loss: 0.0451 - acc: 0.9960\n",
      "Epoch 76/300\n",
      "756/756 [==============================] - 0s 570us/step - loss: 0.0471 - acc: 0.9960\n",
      "Epoch 77/300\n",
      "756/756 [==============================] - 0s 572us/step - loss: 0.0466 - acc: 0.9960\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 0s 534us/step - loss: 0.0464 - acc: 0.9960\n",
      "Epoch 79/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0448 - acc: 0.9960\n",
      "Epoch 80/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0449 - acc: 0.9960\n",
      "Epoch 81/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0447 - acc: 0.9960\n",
      "Epoch 82/300\n",
      "756/756 [==============================] - 0s 559us/step - loss: 0.0437 - acc: 0.9960\n",
      "Epoch 83/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0444 - acc: 0.9960\n",
      "Epoch 84/300\n",
      "756/756 [==============================] - 0s 567us/step - loss: 0.0476 - acc: 0.9960\n",
      "Epoch 85/300\n",
      "756/756 [==============================] - 0s 559us/step - loss: 0.0448 - acc: 0.9960\n",
      "Epoch 86/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0429 - acc: 0.9974\n",
      "Epoch 87/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0444 - acc: 0.9960\n",
      "Epoch 88/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0475 - acc: 0.9960\n",
      "Epoch 89/300\n",
      "756/756 [==============================] - 0s 563us/step - loss: 0.0456 - acc: 0.9960\n",
      "Epoch 90/300\n",
      "756/756 [==============================] - 0s 524us/step - loss: 0.0437 - acc: 0.9960\n",
      "Epoch 91/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0437 - acc: 0.9960\n",
      "Epoch 92/300\n",
      "756/756 [==============================] - 0s 577us/step - loss: 0.0435 - acc: 0.9974\n",
      "Epoch 93/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0463 - acc: 0.9960\n",
      "Epoch 94/300\n",
      "756/756 [==============================] - 0s 568us/step - loss: 0.0431 - acc: 0.9974\n",
      "Epoch 95/300\n",
      "756/756 [==============================] - 0s 531us/step - loss: 0.0436 - acc: 0.9974\n",
      "Epoch 96/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0450 - acc: 0.9960\n",
      "Epoch 97/300\n",
      "756/756 [==============================] - 0s 570us/step - loss: 0.0429 - acc: 0.9974\n",
      "Epoch 98/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0434 - acc: 0.9974\n",
      "Epoch 99/300\n",
      "756/756 [==============================] - 0s 561us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 100/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0448 - acc: 0.9960\n",
      "Epoch 101/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0447 - acc: 0.9960\n",
      "Epoch 102/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0452 - acc: 0.9960\n",
      "Epoch 103/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0442 - acc: 0.9960\n",
      "Epoch 104/300\n",
      "756/756 [==============================] - 0s 627us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 105/300\n",
      "756/756 [==============================] - 0s 590us/step - loss: 0.0457 - acc: 0.9960\n",
      "Epoch 106/300\n",
      "756/756 [==============================] - 0s 575us/step - loss: 0.0468 - acc: 0.9960\n",
      "Epoch 107/300\n",
      "756/756 [==============================] - 0s 567us/step - loss: 0.0438 - acc: 0.9960\n",
      "Epoch 108/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0447 - acc: 0.9960\n",
      "Epoch 109/300\n",
      "756/756 [==============================] - 0s 606us/step - loss: 0.0434 - acc: 0.9974\n",
      "Epoch 110/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0438 - acc: 0.9960\n",
      "Epoch 111/300\n",
      "756/756 [==============================] - 0s 563us/step - loss: 0.0433 - acc: 0.9974\n",
      "Epoch 112/300\n",
      "756/756 [==============================] - 0s 592us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 113/300\n",
      "756/756 [==============================] - 0s 583us/step - loss: 0.0454 - acc: 0.9960\n",
      "Epoch 114/300\n",
      "756/756 [==============================] - 0s 587us/step - loss: 0.0451 - acc: 0.9960\n",
      "Epoch 115/300\n",
      "756/756 [==============================] - 0s 582us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 116/300\n",
      "756/756 [==============================] - 0s 591us/step - loss: 0.0430 - acc: 0.9974\n",
      "Epoch 117/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0450 - acc: 0.9960\n",
      "Epoch 118/300\n",
      "756/756 [==============================] - 0s 529us/step - loss: 0.0445 - acc: 0.9960\n",
      "Epoch 119/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0433 - acc: 0.9974\n",
      "Epoch 120/300\n",
      "756/756 [==============================] - 0s 540us/step - loss: 0.0430 - acc: 0.9974\n",
      "Epoch 121/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0440 - acc: 0.9960\n",
      "Epoch 122/300\n",
      "756/756 [==============================] - 0s 534us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 123/300\n",
      "756/756 [==============================] - 0s 522us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 124/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 125/300\n",
      "756/756 [==============================] - 0s 538us/step - loss: 0.0430 - acc: 0.9974ETA: 0s - loss: 0.0864 - acc: \n",
      "Epoch 126/300\n",
      "756/756 [==============================] - 0s 540us/step - loss: 0.0441 - acc: 0.9960\n",
      "Epoch 127/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0447 - acc: 0.9960\n",
      "Epoch 128/300\n",
      "756/756 [==============================] - 0s 534us/step - loss: 0.0430 - acc: 0.9974\n",
      "Epoch 129/300\n",
      "756/756 [==============================] - 0s 594us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 130/300\n",
      "756/756 [==============================] - 0s 601us/step - loss: 0.0438 - acc: 0.9960\n",
      "Epoch 131/300\n",
      "756/756 [==============================] - 0s 602us/step - loss: 0.0436 - acc: 0.9960\n",
      "Epoch 132/300\n",
      "756/756 [==============================] - 0s 618us/step - loss: 0.0431 - acc: 0.9974\n",
      "Epoch 133/300\n",
      "756/756 [==============================] - 0s 542us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 134/300\n",
      "756/756 [==============================] - 0s 545us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 135/300\n",
      "756/756 [==============================] - 0s 588us/step - loss: 0.0436 - acc: 0.9974\n",
      "Epoch 136/300\n",
      "756/756 [==============================] - 0s 583us/step - loss: 0.0432 - acc: 0.9974\n",
      "Epoch 137/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 138/300\n",
      "756/756 [==============================] - 0s 549us/step - loss: 0.0433 - acc: 0.9974\n",
      "Epoch 139/300\n",
      "756/756 [==============================] - 0s 550us/step - loss: 0.0430 - acc: 0.9974\n",
      "Epoch 140/300\n",
      "756/756 [==============================] - 0s 552us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 141/300\n",
      "756/756 [==============================] - 0s 560us/step - loss: 0.0429 - acc: 0.9974\n",
      "Epoch 142/300\n",
      "756/756 [==============================] - 0s 534us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 143/300\n",
      "756/756 [==============================] - 0s 528us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 144/300\n",
      "756/756 [==============================] - 0s 546us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 145/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0433 - acc: 0.9974\n",
      "Epoch 146/300\n",
      "756/756 [==============================] - 0s 549us/step - loss: 0.0441 - acc: 0.9960\n",
      "Epoch 147/300\n",
      "756/756 [==============================] - 0s 563us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 148/300\n",
      "756/756 [==============================] - 1s 666us/step - loss: 0.0429 - acc: 0.9974\n",
      "Epoch 149/300\n",
      "756/756 [==============================] - 0s 538us/step - loss: 0.0431 - acc: 0.9974\n",
      "Epoch 150/300\n",
      "756/756 [==============================] - 0s 541us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 151/300\n",
      "756/756 [==============================] - 0s 539us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 152/300\n",
      "756/756 [==============================] - 0s 550us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 153/300\n",
      "756/756 [==============================] - 0s 538us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 154/300\n",
      "756/756 [==============================] - 0s 549us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 155/300\n",
      "756/756 [==============================] - 0s 580us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 156/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0428 - acc: 0.9974\n",
      "Epoch 157/300\n",
      "756/756 [==============================] - 0s 553us/step - loss: 0.0429 - acc: 0.9974\n",
      "Epoch 158/300\n",
      "756/756 [==============================] - 0s 555us/step - loss: 0.0436 - acc: 0.9960\n",
      "Epoch 159/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0429 - acc: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/300\n",
      "756/756 [==============================] - 0s 561us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 161/300\n",
      "756/756 [==============================] - 0s 528us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 162/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 163/300\n",
      "756/756 [==============================] - 0s 554us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 164/300\n",
      "756/756 [==============================] - 0s 544us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 165/300\n",
      "756/756 [==============================] - 0s 527us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 166/300\n",
      "756/756 [==============================] - 0s 530us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 167/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 168/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 169/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 170/300\n",
      "756/756 [==============================] - 0s 528us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 171/300\n",
      "756/756 [==============================] - 0s 530us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 172/300\n",
      "756/756 [==============================] - 0s 532us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 173/300\n",
      "756/756 [==============================] - 0s 528us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 174/300\n",
      "756/756 [==============================] - 0s 529us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 175/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 176/300\n",
      "756/756 [==============================] - 0s 537us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 177/300\n",
      "756/756 [==============================] - 0s 586us/step - loss: 0.0429 - acc: 0.9974\n",
      "Epoch 178/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 179/300\n",
      "756/756 [==============================] - 0s 579us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 180/300\n",
      "756/756 [==============================] - 0s 633us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 181/300\n",
      "756/756 [==============================] - 0s 602us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 182/300\n",
      "756/756 [==============================] - 0s 539us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 183/300\n",
      "756/756 [==============================] - 0s 640us/step - loss: 0.0432 - acc: 0.9974\n",
      "Epoch 184/300\n",
      "756/756 [==============================] - 1s 668us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 185/300\n",
      "756/756 [==============================] - 0s 649us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 186/300\n",
      "756/756 [==============================] - 0s 658us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 187/300\n",
      "756/756 [==============================] - 0s 633us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 188/300\n",
      "756/756 [==============================] - 0s 594us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 189/300\n",
      "756/756 [==============================] - 0s 603us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 190/300\n",
      "756/756 [==============================] - 0s 606us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 191/300\n",
      "756/756 [==============================] - 0s 609us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 192/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 193/300\n",
      "756/756 [==============================] - 0s 584us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 194/300\n",
      "756/756 [==============================] - 0s 615us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 195/300\n",
      "756/756 [==============================] - 1s 1ms/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 196/300\n",
      "756/756 [==============================] - 1s 917us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 197/300\n",
      "756/756 [==============================] - 0s 614us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 198/300\n",
      "756/756 [==============================] - 0s 652us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 199/300\n",
      "756/756 [==============================] - 1s 717us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 200/300\n",
      "756/756 [==============================] - 0s 553us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 201/300\n",
      "756/756 [==============================] - 0s 639us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 202/300\n",
      "756/756 [==============================] - 0s 590us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 203/300\n",
      "756/756 [==============================] - 0s 594us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 204/300\n",
      "756/756 [==============================] - 0s 650us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 205/300\n",
      "756/756 [==============================] - 0s 562us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 206/300\n",
      "756/756 [==============================] - 0s 558us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 207/300\n",
      "756/756 [==============================] - 0s 550us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 208/300\n",
      "756/756 [==============================] - 0s 574us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 209/300\n",
      "756/756 [==============================] - 0s 593us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 210/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 211/300\n",
      "756/756 [==============================] - 0s 610us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 212/300\n",
      "756/756 [==============================] - 0s 589us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 213/300\n",
      "756/756 [==============================] - 0s 582us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 214/300\n",
      "756/756 [==============================] - 0s 592us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 215/300\n",
      "756/756 [==============================] - 0s 578us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 216/300\n",
      "756/756 [==============================] - 0s 646us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 217/300\n",
      "756/756 [==============================] - 0s 581us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 218/300\n",
      "756/756 [==============================] - 0s 579us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 219/300\n",
      "756/756 [==============================] - 0s 584us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 220/300\n",
      "756/756 [==============================] - 0s 630us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 221/300\n",
      "756/756 [==============================] - 0s 584us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 222/300\n",
      "756/756 [==============================] - 0s 580us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 223/300\n",
      "756/756 [==============================] - 0s 583us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 224/300\n",
      "756/756 [==============================] - 0s 564us/step - loss: 0.0427 - acc: 0.9974\n",
      "Epoch 225/300\n",
      "756/756 [==============================] - 0s 554us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 226/300\n",
      "756/756 [==============================] - 0s 565us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 227/300\n",
      "756/756 [==============================] - 0s 596us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 228/300\n",
      "756/756 [==============================] - 0s 599us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 229/300\n",
      "756/756 [==============================] - 0s 644us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 230/300\n",
      "756/756 [==============================] - 0s 632us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 231/300\n",
      "756/756 [==============================] - 0s 600us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 232/300\n",
      "756/756 [==============================] - 0s 564us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 233/300\n",
      "756/756 [==============================] - 0s 555us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 234/300\n",
      "756/756 [==============================] - 0s 574us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 235/300\n",
      "756/756 [==============================] - 0s 562us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 236/300\n",
      "756/756 [==============================] - 0s 554us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 237/300\n",
      "756/756 [==============================] - 0s 558us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 238/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 239/300\n",
      "756/756 [==============================] - 0s 561us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 240/300\n",
      "756/756 [==============================] - 0s 585us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 0s 586us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 242/300\n",
      "756/756 [==============================] - 0s 554us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 243/300\n",
      "756/756 [==============================] - 0s 594us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 244/300\n",
      "756/756 [==============================] - 0s 581us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 245/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 246/300\n",
      "756/756 [==============================] - 0s 538us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 247/300\n",
      "756/756 [==============================] - 0s 533us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 248/300\n",
      "756/756 [==============================] - 0s 558us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 249/300\n",
      "756/756 [==============================] - 0s 536us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 250/300\n",
      "756/756 [==============================] - 0s 537us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 251/300\n",
      "756/756 [==============================] - 0s 538us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 252/300\n",
      "756/756 [==============================] - 0s 553us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 253/300\n",
      "756/756 [==============================] - 0s 542us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 254/300\n",
      "756/756 [==============================] - 0s 549us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 255/300\n",
      "756/756 [==============================] - 0s 574us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 256/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 257/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 258/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 259/300\n",
      "756/756 [==============================] - 0s 552us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 260/300\n",
      "756/756 [==============================] - 0s 603us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 261/300\n",
      "756/756 [==============================] - 0s 562us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 262/300\n",
      "756/756 [==============================] - 0s 555us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 263/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 264/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 265/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 266/300\n",
      "756/756 [==============================] - 0s 552us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 267/300\n",
      "756/756 [==============================] - 0s 557us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 268/300\n",
      "756/756 [==============================] - 0s 557us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 269/300\n",
      "756/756 [==============================] - 0s 563us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 270/300\n",
      "756/756 [==============================] - 0s 561us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 271/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 272/300\n",
      "756/756 [==============================] - 0s 598us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 273/300\n",
      "756/756 [==============================] - 0s 581us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 274/300\n",
      "756/756 [==============================] - 0s 596us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 275/300\n",
      "756/756 [==============================] - 0s 582us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 276/300\n",
      "756/756 [==============================] - 0s 573us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 277/300\n",
      "756/756 [==============================] - 0s 558us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 278/300\n",
      "756/756 [==============================] - 0s 552us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 279/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 280/300\n",
      "756/756 [==============================] - 0s 558us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 281/300\n",
      "756/756 [==============================] - 0s 556us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 282/300\n",
      "756/756 [==============================] - 0s 553us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 283/300\n",
      "756/756 [==============================] - 0s 541us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 284/300\n",
      "756/756 [==============================] - 0s 543us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 285/300\n",
      "756/756 [==============================] - 0s 607us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 286/300\n",
      "756/756 [==============================] - 0s 623us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 287/300\n",
      "756/756 [==============================] - 0s 553us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 288/300\n",
      "756/756 [==============================] - 0s 553us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 289/300\n",
      "756/756 [==============================] - 0s 550us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 290/300\n",
      "756/756 [==============================] - 0s 559us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 291/300\n",
      "756/756 [==============================] - 0s 551us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 292/300\n",
      "756/756 [==============================] - 0s 566us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 293/300\n",
      "756/756 [==============================] - 0s 577us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 294/300\n",
      "756/756 [==============================] - 0s 555us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 295/300\n",
      "756/756 [==============================] - 0s 567us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 296/300\n",
      "756/756 [==============================] - 0s 555us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 297/300\n",
      "756/756 [==============================] - 0s 567us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 298/300\n",
      "756/756 [==============================] - 0s 587us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 299/300\n",
      "756/756 [==============================] - 0s 575us/step - loss: 0.0426 - acc: 0.9974\n",
      "Epoch 300/300\n",
      "756/756 [==============================] - 0s 569us/step - loss: 0.0426 - acc: 0.9974\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(input_train,y_train,batch_size=2,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66, 70, 68, 45, 64, 61, 77, 74, 64, 67, 41, 53, 81, 42, 68, 50, 46, 71, 76, 65, 64, 44, 56, 77, 41, 62, 42, 76, 51, 60, 65, 58, 73, 72, 55, 48, 71, 80, 67, 73, 40, 75, 62, 82, 56, 76, 52, 65, 66, 68, 41, 74, 46, 51, 61, 63, 41, 42, 44, 57, 82, 49, 60, 75, 51, 42, 76, 72, 53, 61, 83, 76, 44, 77, 49, 60, 72, 50, 44, 73, 75, 51, 69, 60, 56, 68, 74, 53, 63, 40, 51, 44, 42, 67, 42, 62, 46, 51, 52, 82, 73, 67, 69, 80, 80, 74, 73, 61, 42, 74, 74, 60, 71, 45, 45, 76, 53, 84, 40, 84, 49, 84, 70, 54, 76, 77, 61, 48, 45, 77, 71, 51, 58, 77, 67, 82, 45, 51, 69, 56, 77, 69, 47, 57, 45, 66, 70, 43, 43, 57, 40, 52, 83, 44, 46, 73, 54, 52, 60, 83, 68, 54, 54, 80, 70, 83, 61, 80, 48, 57, 50, 63, 64, 59, 62, 40, 54, 76, 57, 67, 54, 59, 63, 80, 40, 62, 82, 50, 81, 68, 57, 84, 54, 71, 78, 48, 62, 83, 71, 55, 46, 61, 56, 63, 51, 83, 77, 77, 49, 43, 70, 60, 43, 51, 62, 63, 49, 59, 46, 50, 71, 63, 53, 43, 50, 77, 58, 69, 71, 50, 46, 72, 68, 68, 52, 75, 75, 72, 84, 80, 58, 41, 57, 65, 55, 64, 74, 56, 79, 74, 49, 63, 52, 70, 61]\n",
      "[66, 70, 68, 45, 64, 61, 77, 74, 64, 67, 41, 53, 81, 42, 68, 50, 46, 71, 76, 65, 64, 44, 56, 77, 41, 62, 42, 76, 51, 60, 65, 58, 73, 72, 55, 48, 71, 80, 67, 73, 40, 75, 62, 82, 56, 76, 52, 65, 66, 68, 41, 74, 46, 51, 61, 63, 41, 42, 76, 57, 82, 48, 60, 75, 51, 42, 64, 72, 53, 61, 83, 76, 44, 77, 49, 60, 72, 50, 44, 73, 74, 51, 69, 60, 56, 68, 62, 53, 63, 40, 51, 44, 42, 67, 42, 62, 46, 51, 52, 82, 73, 67, 69, 80, 80, 74, 73, 61, 42, 74, 74, 60, 71, 45, 45, 76, 53, 84, 40, 84, 49, 84, 70, 54, 76, 77, 61, 48, 45, 77, 71, 49, 58, 77, 67, 81, 45, 51, 69, 56, 77, 69, 47, 57, 45, 66, 70, 43, 43, 57, 40, 52, 83, 44, 46, 73, 54, 52, 60, 83, 68, 54, 54, 80, 70, 83, 61, 80, 48, 57, 50, 63, 64, 59, 62, 40, 54, 76, 57, 67, 54, 59, 63, 80, 40, 62, 82, 48, 81, 68, 57, 84, 54, 71, 78, 48, 62, 83, 71, 55, 46, 61, 56, 51, 51, 83, 77, 77, 49, 43, 70, 60, 43, 51, 62, 63, 49, 59, 46, 50, 71, 63, 53, 43, 50, 77, 58, 69, 71, 50, 46, 72, 68, 68, 52, 75, 75, 72, 84, 80, 58, 41, 57, 65, 55, 64, 74, 56, 79, 74, 49, 63, 52, 70, 61]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 1, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "总量： 255 错误量： 9\n",
      "正确率： 0.9647058823529412\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test)\n",
    "predict_note = []\n",
    "for i in range(len(predict)):\n",
    "    index = np.argmax(predict[i])\n",
    "    predict_note.append(index+40)\n",
    "\n",
    "num = 0\n",
    "wrong_num = 0\n",
    "for i in range(len(predict_note)):\n",
    "    if abs(predict_note[i] - test_standard[i])==0:\n",
    "        num += 1\n",
    "    else:\n",
    "        wrong_num += 1\n",
    "accuracy = num/len(predict_note)\n",
    "print(predict_note)\n",
    "print(test_standard)\n",
    "dis = []\n",
    "for i in range(len(predict_note)):\n",
    "    dis.append(abs(predict_note[i] - test_standard[i]))\n",
    "print(dis)\n",
    "print(\"总量：\",len(predict_note),\"错误量：\",wrong_num)\n",
    "print(\"正确率：\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, acc, 'b', label='acc')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
