{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(2,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/wrong_train_fdomain.json\")\n",
    "obj_r2 = open(\"./test/json/wrong_train_type_fdomain.json\")\n",
    "input_train = json.load(obj_r)\n",
    "input_train = np.array(input_train)\n",
    "print(len(input_train))\n",
    "y = json.load(obj_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.zeros((len(y),2))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    if y[i] != 0:\n",
    "        y_train[i][1] = 1\n",
    "    else:\n",
    "        y_train[i][0] = 1\n",
    "print(y_train)\n",
    "x_val=input_train[0:20]\n",
    "y_val=y_train[0:20]\n",
    "input_train=input_train[20:]\n",
    "y_train=y_train[20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 2.9651 - acc: 0.5667 - val_loss: 0.3310 - val_acc: 0.9500\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 1.1048 - acc: 0.6667 - val_loss: 0.5015 - val_acc: 0.9500\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 798us/step - loss: 0.8353 - acc: 0.6667 - val_loss: 0.4443 - val_acc: 0.9500\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 765us/step - loss: 0.8136 - acc: 0.6667 - val_loss: 0.3894 - val_acc: 0.9500\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.7927 - acc: 0.6667 - val_loss: 0.4294 - val_acc: 0.9500\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.7838 - acc: 0.6667 - val_loss: 0.3937 - val_acc: 0.9500\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 664us/step - loss: 0.7290 - acc: 0.6833 - val_loss: 0.4654 - val_acc: 0.9500\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.7383 - acc: 0.6667 - val_loss: 0.4153 - val_acc: 0.9500\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.6319 - acc: 0.6833 - val_loss: 0.3315 - val_acc: 0.9500\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 765us/step - loss: 0.5960 - acc: 0.6833 - val_loss: 0.2570 - val_acc: 0.9500\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 598us/step - loss: 0.6516 - acc: 0.6333 - val_loss: 0.5334 - val_acc: 0.9000\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 565us/step - loss: 0.6033 - acc: 0.6833 - val_loss: 0.2183 - val_acc: 0.9000\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 765us/step - loss: 0.5641 - acc: 0.7000 - val_loss: 0.3982 - val_acc: 0.8500\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 798us/step - loss: 0.5459 - acc: 0.7667 - val_loss: 0.2996 - val_acc: 0.9000\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5416 - acc: 0.7667 - val_loss: 0.2884 - val_acc: 0.9000\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5401 - acc: 0.7667 - val_loss: 0.2912 - val_acc: 0.9000\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5406 - acc: 0.7667 - val_loss: 0.2855 - val_acc: 0.8500\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5434 - acc: 0.7167 - val_loss: 0.2993 - val_acc: 0.9000\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.5383 - acc: 0.7667 - val_loss: 0.2975 - val_acc: 0.9000\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.5398 - acc: 0.7500 - val_loss: 0.2981 - val_acc: 0.9000\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.5398 - acc: 0.7333 - val_loss: 0.5612 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.5893 - acc: 0.7167 - val_loss: 0.2534 - val_acc: 0.8500\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.5353 - acc: 0.7667 - val_loss: 0.2367 - val_acc: 0.8500\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5340 - acc: 0.7667 - val_loss: 0.2372 - val_acc: 0.8500\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.5344 - acc: 0.7667 - val_loss: 0.2553 - val_acc: 0.8500\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5340 - acc: 0.7667 - val_loss: 0.2829 - val_acc: 0.8500\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5328 - acc: 0.7667 - val_loss: 0.2622 - val_acc: 0.8500\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 765us/step - loss: 0.5392 - acc: 0.7500 - val_loss: 0.2561 - val_acc: 0.8500\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5301 - acc: 0.7667 - val_loss: 0.2499 - val_acc: 0.9000\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 831us/step - loss: 0.5320 - acc: 0.7667 - val_loss: 0.2805 - val_acc: 0.9000\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.5314 - acc: 0.7667 - val_loss: 0.2555 - val_acc: 0.9000\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5301 - acc: 0.7667 - val_loss: 0.2850 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 748us/step - loss: 0.5292 - acc: 0.7667 - val_loss: 0.2785 - val_acc: 0.8500\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5382 - acc: 0.7500 - val_loss: 0.2777 - val_acc: 0.9000\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.5285 - acc: 0.7667 - val_loss: 0.2926 - val_acc: 0.9000\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 781us/step - loss: 0.5309 - acc: 0.7667 - val_loss: 0.2872 - val_acc: 0.9000\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 848us/step - loss: 1.6096 - acc: 0.7333 - val_loss: 0.2986 - val_acc: 0.8500\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 781us/step - loss: 0.5282 - acc: 0.7500 - val_loss: 0.2807 - val_acc: 0.8500\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 682us/step - loss: 0.5213 - acc: 0.7500 - val_loss: 0.2807 - val_acc: 0.8500\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5241 - acc: 0.7333 - val_loss: 0.2999 - val_acc: 0.8500\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 549us/step - loss: 0.5205 - acc: 0.7667 - val_loss: 0.3473 - val_acc: 0.8500\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.5174 - acc: 0.7667 - val_loss: 0.3365 - val_acc: 0.8500\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5185 - acc: 0.7667 - val_loss: 0.2306 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5160 - acc: 0.7667 - val_loss: 0.3121 - val_acc: 0.8500\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5167 - acc: 0.7667 - val_loss: 0.3061 - val_acc: 0.8500\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5171 - acc: 0.7667 - val_loss: 0.2946 - val_acc: 0.8500\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 565us/step - loss: 0.5144 - acc: 0.7667 - val_loss: 0.2974 - val_acc: 0.8500\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 814us/step - loss: 0.5260 - acc: 0.7333 - val_loss: 0.3095 - val_acc: 0.8500\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 765us/step - loss: 0.5157 - acc: 0.7667 - val_loss: 0.2980 - val_acc: 0.8500\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.5137 - acc: 0.7667 - val_loss: 0.2901 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.5148 - acc: 0.7667 - val_loss: 0.3274 - val_acc: 0.9000\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 565us/step - loss: 0.5135 - acc: 0.7667 - val_loss: 0.2804 - val_acc: 0.9000\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 598us/step - loss: 0.5144 - acc: 0.7667 - val_loss: 0.3111 - val_acc: 0.9000\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5135 - acc: 0.7667 - val_loss: 0.3996 - val_acc: 0.8500\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5160 - acc: 0.7500 - val_loss: 0.4565 - val_acc: 0.9500\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 814us/step - loss: 0.6017 - acc: 0.7500 - val_loss: 0.3793 - val_acc: 0.8500\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5168 - acc: 0.7500 - val_loss: 0.3742 - val_acc: 0.8500\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5162 - acc: 0.7500 - val_loss: 0.3690 - val_acc: 0.8500\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5110 - acc: 0.7667 - val_loss: 0.3774 - val_acc: 0.8500\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.5171 - acc: 0.7500 - val_loss: 0.3690 - val_acc: 0.8500\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 781us/step - loss: 0.5161 - acc: 0.7500 - val_loss: 0.3646 - val_acc: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5158 - acc: 0.7500 - val_loss: 0.3663 - val_acc: 0.8500\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.5117 - acc: 0.7667 - val_loss: 0.3673 - val_acc: 0.8500\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5141 - acc: 0.7667 - val_loss: 0.3694 - val_acc: 0.8500\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5086 - acc: 0.7667 - val_loss: 0.3685 - val_acc: 0.8500\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 598us/step - loss: 0.5085 - acc: 0.7667 - val_loss: 0.3676 - val_acc: 0.8500\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.5084 - acc: 0.7667 - val_loss: 0.3490 - val_acc: 0.8500\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.5076 - acc: 0.7667 - val_loss: 0.3608 - val_acc: 0.8500\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5082 - acc: 0.7500 - val_loss: 0.3889 - val_acc: 0.8500\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.5075 - acc: 0.7667 - val_loss: 0.3951 - val_acc: 0.8500\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.5060 - acc: 0.7667 - val_loss: 0.3865 - val_acc: 0.8500\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 914us/step - loss: 0.5052 - acc: 0.7667 - val_loss: 0.3566 - val_acc: 0.8500\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.5146 - acc: 0.7500 - val_loss: 0.3943 - val_acc: 0.8500\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5117 - acc: 0.7500 - val_loss: 0.3764 - val_acc: 0.8500\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.5542 - acc: 0.7167 - val_loss: 0.5396 - val_acc: 0.8500\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 549us/step - loss: 0.5193 - acc: 0.7667 - val_loss: 0.4453 - val_acc: 0.8500\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5100 - acc: 0.7333 - val_loss: 0.4386 - val_acc: 0.8500\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.5079 - acc: 0.7667 - val_loss: 0.3972 - val_acc: 0.8000\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 549us/step - loss: 0.5104 - acc: 0.7500 - val_loss: 0.3861 - val_acc: 0.8000\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.5041 - acc: 0.7667 - val_loss: 0.3747 - val_acc: 0.8500\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5031 - acc: 0.7667 - val_loss: 0.3799 - val_acc: 0.8500\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.5043 - acc: 0.7667 - val_loss: 0.3876 - val_acc: 0.8500\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 798us/step - loss: 0.5016 - acc: 0.7667 - val_loss: 0.3685 - val_acc: 0.8500\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5002 - acc: 0.7667 - val_loss: 0.3778 - val_acc: 0.8500\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.4999 - acc: 0.7667 - val_loss: 0.3688 - val_acc: 0.8500\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.5008 - acc: 0.7667 - val_loss: 0.3929 - val_acc: 0.8500\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 715us/step - loss: 0.5003 - acc: 0.7667 - val_loss: 0.3971 - val_acc: 0.8500\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 632us/step - loss: 0.5004 - acc: 0.7667 - val_loss: 0.3828 - val_acc: 0.8500\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.5002 - acc: 0.7667 - val_loss: 0.3889 - val_acc: 0.8500\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 815us/step - loss: 0.5072 - acc: 0.7500 - val_loss: 0.3875 - val_acc: 0.8500\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 814us/step - loss: 0.5071 - acc: 0.7500 - val_loss: 0.3887 - val_acc: 0.8500\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 815us/step - loss: 0.4979 - acc: 0.7667 - val_loss: 0.3904 - val_acc: 0.8500\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 781us/step - loss: 0.4989 - acc: 0.7667 - val_loss: 0.3370 - val_acc: 0.8500\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 748us/step - loss: 0.4982 - acc: 0.7667 - val_loss: 0.3898 - val_acc: 0.8500\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.5015 - acc: 0.7667 - val_loss: 0.3768 - val_acc: 0.8500\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 665us/step - loss: 0.5062 - acc: 0.7500 - val_loss: 0.3828 - val_acc: 0.8500\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.4965 - acc: 0.7667 - val_loss: 0.3696 - val_acc: 0.8500\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 565us/step - loss: 0.5960 - acc: 0.7667 - val_loss: 0.4165 - val_acc: 0.9000\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.4953 - acc: 0.7667 - val_loss: 0.4155 - val_acc: 0.9000\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 798us/step - loss: 0.4943 - acc: 0.7667 - val_loss: 0.4147 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(input_train,y_train,batch_size=15,epochs=100,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/wrong_test_fdomain.json\")\n",
    "obj_r2 = open(\"./test/json/wrong_test_type_fdomain.json\")\n",
    "\n",
    "\n",
    "test = json.load(obj_r)\n",
    "test = np.array(test)\n",
    "t = json.load(obj_r2)\n",
    "print(len(test))\n",
    "t = np.array(t)\n",
    "for i in range(len(t)):\n",
    "    if t[i]!=0:\n",
    "        t[i] = 1\n",
    "test_standard = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实际： [1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1]\n",
      "预测 [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "预测概率 [0.017334223, 1.0, 0.2047863, 0.07450569, 0.1809575, 1.0, 0.9997599, 0.69028664, 1.0, 0.9999995, 0.99999964, 0.81673133, 1.0, 1.0, 1.0, 0.69028664, 1.0, 0.99629843, 1.0, 0.69028664]\n",
      "1 0\n",
      "2 0\n",
      "4 0\n",
      "7 1\n",
      "9 0\n",
      "12 0\n",
      "15 1\n",
      "17 0\n",
      "19 1\n",
      "总量： 20 错误量： 9 0量： 6\n",
      "正确率： 0.55\n"
     ]
    }
   ],
   "source": [
    "wrongfile_list=[]\n",
    "predict = model.predict(test)\n",
    "predict_type = []\n",
    "predict_proba = []\n",
    "for i in range(len(predict)):\n",
    "    index = np.argmax(predict[i])\n",
    "    predict_proba.append(predict[i][index]) \n",
    "    predict_type.append(index)\n",
    "\n",
    "print(\"实际：\",test_standard)\n",
    "print(\"预测\",predict_type)\n",
    "print(\"预测概率\",predict_proba)\n",
    "num = 0\n",
    "wrong_num = 0\n",
    "num_0 = 0\n",
    "for i in range(len(predict_type)):\n",
    "    if test_standard[i]==0:\n",
    "        num_0 += 1\n",
    "    if abs(predict_type[i] - test_standard[i])==0:\n",
    "        num += 1\n",
    "    else:\n",
    "        wrong_num += 1\n",
    "        print(i,test_standard[i])\n",
    "accuracy = num/len(predict_type)\n",
    "# print(predict_note)\n",
    "# print(test_standard)\n",
    "print(\"总量：\",len(predict_type),\"错误量：\",wrong_num,\"0量：\",num_0)\n",
    "print(\"正确率：\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n+WnM6ZudYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "print(history_dict.keys())\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
