{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dropout(0.13))\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dropout(0.13))\n",
    "model.add(layers.Dense(45,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/datasetx_train2.json\")\n",
    "obj_r2 = open(\"./test/json/datasetx_result2.json\")\n",
    "input_train = json.load(obj_r)\n",
    "input_train = np.array(input_train)\n",
    "print(len(input_train))\n",
    "y = json.load(obj_r2)\n",
    "y = np.array(y)\n",
    "y = y*2093.004\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fre_to_note_piano(fre):\n",
    "    index = round(math.log(fre / 27.5,2**(1/12)))\n",
    "    dict = [\"A1 \",\"#A1 \",\"B1 \",\"C2 \",\"#C2 \",\"D2 \",\"#D2 \",\"E2 \",\"F2 \",\"#F2 \",\"G2 \",\"#G2 \",\"A2 \",\"#A2 \",\"B2 \",\"C3 \",\"#C3 \",\"D3 \",\"#D3 \",\"E3 \",\"F3 \",\"#F3 \",\"G3 \",\"#G3 \",\"A3 \",\"#A3 \",\"B3 \",\"C4 \",\"#C4 \",\"D4 \",\"#D4 \",\"E4 \",\"F4 \",\"#F4 \",\"G4 \",\"#G4 \",\"A4 \", \"#A4 \", \"B4 \", \"C5 \", \"#C5 \", \"D5 \", \"#D5 \", \"E5 \",\"F5 \",\"#F5 \",\"G5 \",\"#G5 \",\"A5 \", \"#A5 \", \"B5 \", \"C6 \", \"#C6 \", \"D6 \", \"#D6 \", \"E6 \",\n",
    "    \"F6 \",\"#F6 \",\"G6 \",\"#G6 \",\"A6 \", \"#A6 \", \"B6 \", \"C7 \", \"#C7 \", \"D7 \", \"#D7 \", \"E7 \",\"F7 \",\"#F7 \",\"G7 \",\"#G7 \",\"A7 \", \"#A7 \", \"B7 \", \"C8 \",\"#C8 \",\"D8 \",\"#D8 \",\"E8 \",\"F8 \",\"#F8 \",\"G8 \",\"#G8 \",\"A8 \",\"#A8 \",\"B8 \",\"C9 \",\"#C9 \", \"D9 \", \"#D9 \", \"E9 \",\"F9 \",\"#F9 \",\"G9 \",\"#G9 \",\"A9 \", \"#A9 \", \"B9 \", \"C10 \"]\n",
    "    return index+21\n",
    "y_train = np.zeros((len(y),45))\n",
    "test_standard = []\n",
    "for i in range(len(y)):\n",
    "    index = fre_to_note_piano(y[i])\n",
    "    y_train[i][index-40] = 1\n",
    "    100\n",
    "    \n",
    "x_val=input_train[0:50]\n",
    "y_val=y_train[0:50]\n",
    "input_train=input_train[50:]\n",
    "y_train=y_train[50:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 706 samples, validate on 50 samples\n",
      "Epoch 1/400\n",
      "706/706 [==============================] - 0s 681us/step - loss: 3.8026 - acc: 0.0453 - val_loss: 3.7894 - val_acc: 0.1000\n",
      "Epoch 2/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 3.7737 - acc: 0.0977 - val_loss: 3.7507 - val_acc: 0.1400\n",
      "Epoch 3/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 3.7208 - acc: 0.1615 - val_loss: 3.6766 - val_acc: 0.1000\n",
      "Epoch 4/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 3.6394 - acc: 0.1686 - val_loss: 3.5681 - val_acc: 0.1800\n",
      "Epoch 5/400\n",
      "706/706 [==============================] - 0s 206us/step - loss: 3.5177 - acc: 0.2167 - val_loss: 3.4290 - val_acc: 0.2400\n",
      "Epoch 6/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 3.3600 - acc: 0.2833 - val_loss: 3.2275 - val_acc: 0.2800\n",
      "Epoch 7/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 3.1625 - acc: 0.2861 - val_loss: 3.0084 - val_acc: 0.3600\n",
      "Epoch 8/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 2.9433 - acc: 0.3640 - val_loss: 2.7574 - val_acc: 0.4000\n",
      "Epoch 9/400\n",
      "706/706 [==============================] - 0s 280us/step - loss: 2.7347 - acc: 0.4037 - val_loss: 2.4730 - val_acc: 0.5000\n",
      "Epoch 10/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 2.5187 - acc: 0.4405 - val_loss: 2.2401 - val_acc: 0.4600\n",
      "Epoch 11/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 2.3043 - acc: 0.4830 - val_loss: 1.9700 - val_acc: 0.6000\n",
      "Epoch 12/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 2.1044 - acc: 0.5212 - val_loss: 1.7604 - val_acc: 0.6800\n",
      "Epoch 13/400\n",
      "706/706 [==============================] - 0s 288us/step - loss: 1.9028 - acc: 0.6161 - val_loss: 1.5934 - val_acc: 0.6600\n",
      "Epoch 14/400\n",
      "706/706 [==============================] - 0s 267us/step - loss: 1.7344 - acc: 0.6317 - val_loss: 1.4077 - val_acc: 0.6800\n",
      "Epoch 15/400\n",
      "706/706 [==============================] - 0s 260us/step - loss: 1.6085 - acc: 0.6431 - val_loss: 1.2391 - val_acc: 0.8200\n",
      "Epoch 16/400\n",
      "706/706 [==============================] - 0s 230us/step - loss: 1.4841 - acc: 0.6884 - val_loss: 1.1016 - val_acc: 0.8200\n",
      "Epoch 17/400\n",
      "706/706 [==============================] - 0s 218us/step - loss: 1.3830 - acc: 0.6657 - val_loss: 0.9944 - val_acc: 0.8400\n",
      "Epoch 18/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 1.3041 - acc: 0.6841 - val_loss: 0.8816 - val_acc: 0.8400\n",
      "Epoch 19/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 1.2030 - acc: 0.7068 - val_loss: 0.7905 - val_acc: 0.8600\n",
      "Epoch 20/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 1.1144 - acc: 0.7408 - val_loss: 0.7330 - val_acc: 0.9000\n",
      "Epoch 21/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 1.0639 - acc: 0.7493 - val_loss: 0.6766 - val_acc: 0.9000\n",
      "Epoch 22/400\n",
      "706/706 [==============================] - 0s 208us/step - loss: 1.0021 - acc: 0.7365 - val_loss: 0.6021 - val_acc: 0.9200\n",
      "Epoch 23/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.9047 - acc: 0.7960 - val_loss: 0.5472 - val_acc: 0.9000\n",
      "Epoch 24/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.8570 - acc: 0.7790 - val_loss: 0.5133 - val_acc: 0.9000\n",
      "Epoch 25/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.8112 - acc: 0.8173 - val_loss: 0.4553 - val_acc: 0.9200\n",
      "Epoch 26/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.7962 - acc: 0.7790 - val_loss: 0.4220 - val_acc: 0.9600\n",
      "Epoch 27/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.7245 - acc: 0.8300 - val_loss: 0.4130 - val_acc: 0.9000\n",
      "Epoch 28/400\n",
      "706/706 [==============================] - 0s 171us/step - loss: 0.7071 - acc: 0.8229 - val_loss: 0.3721 - val_acc: 0.9600\n",
      "Epoch 29/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.6668 - acc: 0.8329 - val_loss: 0.3502 - val_acc: 0.9400\n",
      "Epoch 30/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.6229 - acc: 0.8626 - val_loss: 0.3404 - val_acc: 0.9400\n",
      "Epoch 31/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.6323 - acc: 0.8456 - val_loss: 0.3040 - val_acc: 0.9400\n",
      "Epoch 32/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.5897 - acc: 0.8428 - val_loss: 0.2897 - val_acc: 0.9400\n",
      "Epoch 33/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.5617 - acc: 0.8697 - val_loss: 0.2681 - val_acc: 0.9400\n",
      "Epoch 34/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.5284 - acc: 0.8796 - val_loss: 0.2536 - val_acc: 0.9400\n",
      "Epoch 35/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.5228 - acc: 0.8796 - val_loss: 0.2493 - val_acc: 0.9600\n",
      "Epoch 36/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.4829 - acc: 0.8853 - val_loss: 0.2223 - val_acc: 0.9400\n",
      "Epoch 37/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.4761 - acc: 0.8754 - val_loss: 0.2249 - val_acc: 0.9400\n",
      "Epoch 38/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.4419 - acc: 0.8980 - val_loss: 0.2044 - val_acc: 0.9600\n",
      "Epoch 39/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.4451 - acc: 0.8839 - val_loss: 0.1958 - val_acc: 0.9600\n",
      "Epoch 40/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.4129 - acc: 0.8924 - val_loss: 0.1805 - val_acc: 0.9600\n",
      "Epoch 41/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.4076 - acc: 0.8867 - val_loss: 0.1697 - val_acc: 0.9600\n",
      "Epoch 42/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.4000 - acc: 0.8966 - val_loss: 0.1686 - val_acc: 0.9400\n",
      "Epoch 43/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.3680 - acc: 0.8980 - val_loss: 0.1604 - val_acc: 0.9400\n",
      "Epoch 44/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.3468 - acc: 0.9023 - val_loss: 0.1536 - val_acc: 0.9600\n",
      "Epoch 45/400\n",
      "706/706 [==============================] - 0s 208us/step - loss: 0.3496 - acc: 0.9278 - val_loss: 0.1678 - val_acc: 0.9600\n",
      "Epoch 46/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.3528 - acc: 0.9008 - val_loss: 0.1514 - val_acc: 0.9600\n",
      "Epoch 47/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.3158 - acc: 0.9306 - val_loss: 0.1278 - val_acc: 0.9600\n",
      "Epoch 48/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.3437 - acc: 0.9164 - val_loss: 0.1314 - val_acc: 0.9600\n",
      "Epoch 49/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.3001 - acc: 0.9150 - val_loss: 0.1344 - val_acc: 0.9600\n",
      "Epoch 50/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.3487 - acc: 0.9079 - val_loss: 0.1342 - val_acc: 0.9600\n",
      "Epoch 51/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.3133 - acc: 0.9108 - val_loss: 0.1171 - val_acc: 0.9600\n",
      "Epoch 52/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.3139 - acc: 0.9221 - val_loss: 0.1138 - val_acc: 0.9600\n",
      "Epoch 53/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.2616 - acc: 0.9391 - val_loss: 0.1068 - val_acc: 0.9600\n",
      "Epoch 54/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.2645 - acc: 0.9249 - val_loss: 0.0966 - val_acc: 0.9800\n",
      "Epoch 55/400\n",
      "706/706 [==============================] - 0s 205us/step - loss: 0.2523 - acc: 0.9334 - val_loss: 0.0953 - val_acc: 0.9800\n",
      "Epoch 56/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 0.2552 - acc: 0.9292 - val_loss: 0.0937 - val_acc: 0.9600\n",
      "Epoch 57/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.2641 - acc: 0.9235 - val_loss: 0.0931 - val_acc: 0.9600\n",
      "Epoch 58/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.2348 - acc: 0.9419 - val_loss: 0.0876 - val_acc: 0.9800\n",
      "Epoch 59/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.2518 - acc: 0.9377 - val_loss: 0.0895 - val_acc: 0.9600\n",
      "Epoch 60/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.2342 - acc: 0.9306 - val_loss: 0.0802 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.2300 - acc: 0.9348 - val_loss: 0.0889 - val_acc: 0.9600\n",
      "Epoch 62/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.2076 - acc: 0.9448 - val_loss: 0.0857 - val_acc: 0.9600\n",
      "Epoch 63/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.2297 - acc: 0.9377 - val_loss: 0.0861 - val_acc: 0.9600\n",
      "Epoch 64/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.2351 - acc: 0.9320 - val_loss: 0.0794 - val_acc: 0.9600\n",
      "Epoch 65/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.2118 - acc: 0.9419 - val_loss: 0.0771 - val_acc: 0.9600\n",
      "Epoch 66/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.2003 - acc: 0.9462 - val_loss: 0.0859 - val_acc: 0.9600\n",
      "Epoch 67/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.1902 - acc: 0.9448 - val_loss: 0.0826 - val_acc: 0.9600\n",
      "Epoch 68/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.1971 - acc: 0.9448 - val_loss: 0.0744 - val_acc: 0.9600\n",
      "Epoch 69/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.2023 - acc: 0.9462 - val_loss: 0.0753 - val_acc: 0.9600\n",
      "Epoch 70/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.1949 - acc: 0.9405 - val_loss: 0.0604 - val_acc: 0.9800\n",
      "Epoch 71/400\n",
      "706/706 [==============================] - 0s 170us/step - loss: 0.1633 - acc: 0.9518 - val_loss: 0.0650 - val_acc: 0.9800\n",
      "Epoch 72/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.1951 - acc: 0.9462 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 73/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.1627 - acc: 0.9533 - val_loss: 0.0611 - val_acc: 0.9800\n",
      "Epoch 74/400\n",
      "706/706 [==============================] - 0s 212us/step - loss: 0.1816 - acc: 0.9490 - val_loss: 0.0650 - val_acc: 0.9600\n",
      "Epoch 75/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.1579 - acc: 0.9575 - val_loss: 0.0533 - val_acc: 1.0000\n",
      "Epoch 76/400\n",
      "706/706 [==============================] - 0s 171us/step - loss: 0.1706 - acc: 0.9547 - val_loss: 0.0627 - val_acc: 0.9800\n",
      "Epoch 77/400\n",
      "706/706 [==============================] - 0s 205us/step - loss: 0.1484 - acc: 0.9547 - val_loss: 0.0571 - val_acc: 0.9800\n",
      "Epoch 78/400\n",
      "706/706 [==============================] - 0s 205us/step - loss: 0.1746 - acc: 0.9504 - val_loss: 0.0536 - val_acc: 0.9800\n",
      "Epoch 79/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.1750 - acc: 0.9490 - val_loss: 0.0567 - val_acc: 0.9800\n",
      "Epoch 80/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.1661 - acc: 0.9575 - val_loss: 0.0716 - val_acc: 0.9600\n",
      "Epoch 81/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.1263 - acc: 0.9618 - val_loss: 0.0561 - val_acc: 0.9600\n",
      "Epoch 82/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.1286 - acc: 0.9646 - val_loss: 0.0546 - val_acc: 0.9800\n",
      "Epoch 83/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.1381 - acc: 0.9603 - val_loss: 0.0483 - val_acc: 0.9800\n",
      "Epoch 84/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.1551 - acc: 0.9547 - val_loss: 0.0508 - val_acc: 0.9800\n",
      "Epoch 85/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.1461 - acc: 0.9561 - val_loss: 0.0582 - val_acc: 0.9800\n",
      "Epoch 86/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.1462 - acc: 0.9603 - val_loss: 0.0453 - val_acc: 0.9800\n",
      "Epoch 87/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.1444 - acc: 0.9533 - val_loss: 0.0496 - val_acc: 0.9800\n",
      "Epoch 88/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.1574 - acc: 0.9603 - val_loss: 0.0589 - val_acc: 0.9800\n",
      "Epoch 89/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.1239 - acc: 0.9674 - val_loss: 0.0460 - val_acc: 0.9800\n",
      "Epoch 90/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.1096 - acc: 0.9717 - val_loss: 0.0588 - val_acc: 0.9600\n",
      "Epoch 91/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.1160 - acc: 0.9688 - val_loss: 0.0517 - val_acc: 0.9800\n",
      "Epoch 92/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.1243 - acc: 0.9618 - val_loss: 0.0502 - val_acc: 0.9800\n",
      "Epoch 93/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.1330 - acc: 0.9703 - val_loss: 0.0453 - val_acc: 0.9800\n",
      "Epoch 94/400\n",
      "706/706 [==============================] - 0s 167us/step - loss: 0.1329 - acc: 0.9575 - val_loss: 0.0429 - val_acc: 1.0000\n",
      "Epoch 95/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.1115 - acc: 0.9703 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 96/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.1165 - acc: 0.9646 - val_loss: 0.0392 - val_acc: 1.0000\n",
      "Epoch 97/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.1142 - acc: 0.9646 - val_loss: 0.0515 - val_acc: 0.9800\n",
      "Epoch 98/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.1420 - acc: 0.9561 - val_loss: 0.0476 - val_acc: 0.9800\n",
      "Epoch 99/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.1095 - acc: 0.9618 - val_loss: 0.0543 - val_acc: 0.9600\n",
      "Epoch 100/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.1097 - acc: 0.9745 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 101/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.1207 - acc: 0.9575 - val_loss: 0.0428 - val_acc: 0.9800\n",
      "Epoch 102/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0887 - acc: 0.9773 - val_loss: 0.0433 - val_acc: 0.9800\n",
      "Epoch 103/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.1100 - acc: 0.9618 - val_loss: 0.0465 - val_acc: 0.9800\n",
      "Epoch 104/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0998 - acc: 0.9745 - val_loss: 0.0451 - val_acc: 0.9800\n",
      "Epoch 105/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.1041 - acc: 0.9674 - val_loss: 0.0471 - val_acc: 0.9800\n",
      "Epoch 106/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0943 - acc: 0.9703 - val_loss: 0.0497 - val_acc: 0.9800\n",
      "Epoch 107/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.1302 - acc: 0.9589 - val_loss: 0.0534 - val_acc: 0.9600\n",
      "Epoch 108/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0930 - acc: 0.9731 - val_loss: 0.0387 - val_acc: 1.0000\n",
      "Epoch 109/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.1083 - acc: 0.9646 - val_loss: 0.0418 - val_acc: 1.0000\n",
      "Epoch 110/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.1054 - acc: 0.9646 - val_loss: 0.0406 - val_acc: 0.9800\n",
      "Epoch 111/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.1198 - acc: 0.9646 - val_loss: 0.0469 - val_acc: 0.9800\n",
      "Epoch 112/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0891 - acc: 0.9773 - val_loss: 0.0504 - val_acc: 0.9800\n",
      "Epoch 113/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0843 - acc: 0.9788 - val_loss: 0.0572 - val_acc: 0.9800\n",
      "Epoch 114/400\n",
      "706/706 [==============================] - 0s 208us/step - loss: 0.0907 - acc: 0.9745 - val_loss: 0.0490 - val_acc: 0.9800\n",
      "Epoch 115/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0922 - acc: 0.9788 - val_loss: 0.0333 - val_acc: 1.0000\n",
      "Epoch 116/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0826 - acc: 0.9773 - val_loss: 0.0326 - val_acc: 0.9800\n",
      "Epoch 117/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0849 - acc: 0.9745 - val_loss: 0.0396 - val_acc: 1.0000\n",
      "Epoch 118/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0894 - acc: 0.9731 - val_loss: 0.0429 - val_acc: 0.9800\n",
      "Epoch 119/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0832 - acc: 0.9759 - val_loss: 0.0524 - val_acc: 0.9800\n",
      "Epoch 120/400\n",
      "706/706 [==============================] - 0s 174us/step - loss: 0.0883 - acc: 0.9759 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 121/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/706 [==============================] - 0s 191us/step - loss: 0.0826 - acc: 0.9717 - val_loss: 0.0411 - val_acc: 0.9800\n",
      "Epoch 122/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0840 - acc: 0.9773 - val_loss: 0.0483 - val_acc: 0.9800\n",
      "Epoch 123/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0678 - acc: 0.9830 - val_loss: 0.0461 - val_acc: 0.9800\n",
      "Epoch 124/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0855 - acc: 0.9745 - val_loss: 0.0473 - val_acc: 0.9600\n",
      "Epoch 125/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0675 - acc: 0.9788 - val_loss: 0.0626 - val_acc: 0.9800\n",
      "Epoch 126/400\n",
      "706/706 [==============================] - 0s 171us/step - loss: 0.0702 - acc: 0.9844 - val_loss: 0.0570 - val_acc: 0.9800\n",
      "Epoch 127/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0764 - acc: 0.9773 - val_loss: 0.0718 - val_acc: 0.9600\n",
      "Epoch 128/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0677 - acc: 0.9830 - val_loss: 0.0716 - val_acc: 0.9800\n",
      "Epoch 129/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0661 - acc: 0.9858 - val_loss: 0.0651 - val_acc: 0.9800\n",
      "Epoch 130/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0861 - acc: 0.9802 - val_loss: 0.0736 - val_acc: 0.9800\n",
      "Epoch 131/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0795 - acc: 0.9731 - val_loss: 0.0663 - val_acc: 0.9800\n",
      "Epoch 132/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0913 - acc: 0.9674 - val_loss: 0.0680 - val_acc: 0.9800\n",
      "Epoch 133/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0600 - acc: 0.9844 - val_loss: 0.0408 - val_acc: 0.9800\n",
      "Epoch 134/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0673 - acc: 0.9773 - val_loss: 0.0495 - val_acc: 0.9800\n",
      "Epoch 135/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0885 - acc: 0.9802 - val_loss: 0.0450 - val_acc: 0.9800\n",
      "Epoch 136/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0680 - acc: 0.9788 - val_loss: 0.0548 - val_acc: 0.9800\n",
      "Epoch 137/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0875 - acc: 0.9703 - val_loss: 0.0605 - val_acc: 0.9800\n",
      "Epoch 138/400\n",
      "706/706 [==============================] - 0s 174us/step - loss: 0.0568 - acc: 0.9858 - val_loss: 0.0641 - val_acc: 0.9800\n",
      "Epoch 139/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0745 - acc: 0.9844 - val_loss: 0.0688 - val_acc: 0.9800\n",
      "Epoch 140/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.0647 - acc: 0.9802 - val_loss: 0.0616 - val_acc: 0.9800\n",
      "Epoch 141/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0696 - acc: 0.9788 - val_loss: 0.0556 - val_acc: 0.9800\n",
      "Epoch 142/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0850 - acc: 0.9731 - val_loss: 0.0332 - val_acc: 0.9800\n",
      "Epoch 143/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0689 - acc: 0.9788 - val_loss: 0.0692 - val_acc: 0.9800\n",
      "Epoch 144/400\n",
      "706/706 [==============================] - 0s 170us/step - loss: 0.0590 - acc: 0.9802 - val_loss: 0.0698 - val_acc: 0.9800\n",
      "Epoch 145/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0827 - acc: 0.9717 - val_loss: 0.0743 - val_acc: 0.9800\n",
      "Epoch 146/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0723 - acc: 0.9802 - val_loss: 0.0823 - val_acc: 0.9800\n",
      "Epoch 147/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0670 - acc: 0.9773 - val_loss: 0.0549 - val_acc: 0.9800\n",
      "Epoch 148/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0770 - acc: 0.9759 - val_loss: 0.0629 - val_acc: 0.9800\n",
      "Epoch 149/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.0799 - acc: 0.9773 - val_loss: 0.0581 - val_acc: 0.9800\n",
      "Epoch 150/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0601 - acc: 0.9802 - val_loss: 0.0478 - val_acc: 0.9800\n",
      "Epoch 151/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0512 - acc: 0.9816 - val_loss: 0.0487 - val_acc: 0.9800\n",
      "Epoch 152/400\n",
      "706/706 [==============================] - 0s 174us/step - loss: 0.0790 - acc: 0.9788 - val_loss: 0.0530 - val_acc: 0.9800\n",
      "Epoch 153/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0858 - acc: 0.9731 - val_loss: 0.0493 - val_acc: 0.9800\n",
      "Epoch 154/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0756 - acc: 0.9788 - val_loss: 0.0673 - val_acc: 0.9800\n",
      "Epoch 155/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0682 - acc: 0.9773 - val_loss: 0.0774 - val_acc: 0.9600\n",
      "Epoch 156/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0558 - acc: 0.9830 - val_loss: 0.0669 - val_acc: 0.9800\n",
      "Epoch 157/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0838 - acc: 0.9788 - val_loss: 0.0786 - val_acc: 0.9800\n",
      "Epoch 158/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0721 - acc: 0.9773 - val_loss: 0.0786 - val_acc: 0.9800\n",
      "Epoch 159/400\n",
      "706/706 [==============================] - 0s 206us/step - loss: 0.0602 - acc: 0.9759 - val_loss: 0.0594 - val_acc: 0.9800\n",
      "Epoch 160/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 0.0659 - acc: 0.9802 - val_loss: 0.0781 - val_acc: 0.9800\n",
      "Epoch 161/400\n",
      "706/706 [==============================] - 0s 170us/step - loss: 0.0648 - acc: 0.9773 - val_loss: 0.0661 - val_acc: 0.9800\n",
      "Epoch 162/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0697 - acc: 0.9773 - val_loss: 0.0562 - val_acc: 0.9800\n",
      "Epoch 163/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0495 - acc: 0.9844 - val_loss: 0.0630 - val_acc: 0.9800\n",
      "Epoch 164/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0726 - acc: 0.9830 - val_loss: 0.0754 - val_acc: 0.9800\n",
      "Epoch 165/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0775 - acc: 0.9759 - val_loss: 0.0668 - val_acc: 0.9800\n",
      "Epoch 166/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0620 - acc: 0.9816 - val_loss: 0.0854 - val_acc: 0.9800\n",
      "Epoch 167/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0404 - acc: 0.9858 - val_loss: 0.0546 - val_acc: 0.9800\n",
      "Epoch 168/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0513 - acc: 0.9858 - val_loss: 0.0631 - val_acc: 0.9800\n",
      "Epoch 169/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0622 - acc: 0.9788 - val_loss: 0.0880 - val_acc: 0.9800\n",
      "Epoch 170/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0597 - acc: 0.9802 - val_loss: 0.0784 - val_acc: 0.9800\n",
      "Epoch 171/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0386 - acc: 0.9873 - val_loss: 0.0870 - val_acc: 0.9800\n",
      "Epoch 172/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0501 - acc: 0.9816 - val_loss: 0.0764 - val_acc: 0.9800\n",
      "Epoch 173/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0438 - acc: 0.9858 - val_loss: 0.0914 - val_acc: 0.9800\n",
      "Epoch 174/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0510 - acc: 0.9816 - val_loss: 0.1126 - val_acc: 0.9800\n",
      "Epoch 175/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0546 - acc: 0.9830 - val_loss: 0.0914 - val_acc: 0.9800\n",
      "Epoch 176/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0420 - acc: 0.9802 - val_loss: 0.1067 - val_acc: 0.9800\n",
      "Epoch 177/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0505 - acc: 0.9844 - val_loss: 0.0645 - val_acc: 0.9800\n",
      "Epoch 178/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0440 - acc: 0.9788 - val_loss: 0.0657 - val_acc: 0.9800\n",
      "Epoch 179/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0483 - acc: 0.9873 - val_loss: 0.0783 - val_acc: 0.9800\n",
      "Epoch 180/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.1074 - acc: 0.9674 - val_loss: 0.1007 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0491 - acc: 0.9873 - val_loss: 0.0970 - val_acc: 0.9800\n",
      "Epoch 182/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0454 - acc: 0.9858 - val_loss: 0.0988 - val_acc: 0.9800\n",
      "Epoch 183/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0332 - acc: 0.9915 - val_loss: 0.0962 - val_acc: 0.9800\n",
      "Epoch 184/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0578 - acc: 0.9788 - val_loss: 0.0873 - val_acc: 0.9800\n",
      "Epoch 185/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0438 - acc: 0.9873 - val_loss: 0.1066 - val_acc: 0.9800\n",
      "Epoch 186/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0413 - acc: 0.9802 - val_loss: 0.0864 - val_acc: 0.9800\n",
      "Epoch 187/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0475 - acc: 0.9844 - val_loss: 0.1060 - val_acc: 0.9800\n",
      "Epoch 188/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0495 - acc: 0.9816 - val_loss: 0.0800 - val_acc: 0.9800\n",
      "Epoch 189/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0323 - acc: 0.9901 - val_loss: 0.0779 - val_acc: 0.9800\n",
      "Epoch 190/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 0.0539 - acc: 0.9844 - val_loss: 0.0813 - val_acc: 0.9800\n",
      "Epoch 191/400\n",
      "706/706 [==============================] - 0s 174us/step - loss: 0.0413 - acc: 0.9887 - val_loss: 0.1024 - val_acc: 0.9800\n",
      "Epoch 192/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0695 - acc: 0.9773 - val_loss: 0.1175 - val_acc: 0.9600\n",
      "Epoch 193/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0401 - acc: 0.9844 - val_loss: 0.0944 - val_acc: 0.9800\n",
      "Epoch 194/400\n",
      "706/706 [==============================] - 0s 209us/step - loss: 0.0447 - acc: 0.9858 - val_loss: 0.1059 - val_acc: 0.9800\n",
      "Epoch 195/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0367 - acc: 0.9901 - val_loss: 0.1117 - val_acc: 0.9800\n",
      "Epoch 196/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0561 - acc: 0.9830 - val_loss: 0.1322 - val_acc: 0.9800\n",
      "Epoch 197/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0415 - acc: 0.9830 - val_loss: 0.1010 - val_acc: 0.9800\n",
      "Epoch 198/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0437 - acc: 0.9858 - val_loss: 0.1132 - val_acc: 0.9800\n",
      "Epoch 199/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0397 - acc: 0.9887 - val_loss: 0.1147 - val_acc: 0.9800\n",
      "Epoch 200/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0275 - acc: 0.9915 - val_loss: 0.1307 - val_acc: 0.9800\n",
      "Epoch 201/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0396 - acc: 0.9873 - val_loss: 0.1297 - val_acc: 0.9800\n",
      "Epoch 202/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0409 - acc: 0.9830 - val_loss: 0.1206 - val_acc: 0.9800\n",
      "Epoch 203/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0679 - acc: 0.9802 - val_loss: 0.1248 - val_acc: 0.9800\n",
      "Epoch 204/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0341 - acc: 0.9830 - val_loss: 0.1341 - val_acc: 0.9600\n",
      "Epoch 205/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0404 - acc: 0.9873 - val_loss: 0.1409 - val_acc: 0.9800\n",
      "Epoch 206/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0338 - acc: 0.9873 - val_loss: 0.1437 - val_acc: 0.9600\n",
      "Epoch 207/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0360 - acc: 0.9901 - val_loss: 0.1322 - val_acc: 0.9600\n",
      "Epoch 208/400\n",
      "706/706 [==============================] - 0s 209us/step - loss: 0.0342 - acc: 0.9887 - val_loss: 0.1241 - val_acc: 0.9800\n",
      "Epoch 209/400\n",
      "706/706 [==============================] - 0s 175us/step - loss: 0.0337 - acc: 0.9901 - val_loss: 0.1384 - val_acc: 0.9600\n",
      "Epoch 210/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0512 - acc: 0.9830 - val_loss: 0.1029 - val_acc: 0.9800\n",
      "Epoch 211/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0387 - acc: 0.9858 - val_loss: 0.1088 - val_acc: 0.9800\n",
      "Epoch 212/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0481 - acc: 0.9858 - val_loss: 0.1351 - val_acc: 0.9600\n",
      "Epoch 213/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0438 - acc: 0.9844 - val_loss: 0.1095 - val_acc: 0.9600\n",
      "Epoch 214/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0342 - acc: 0.9929 - val_loss: 0.1434 - val_acc: 0.9600\n",
      "Epoch 215/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0413 - acc: 0.9844 - val_loss: 0.1368 - val_acc: 0.9600\n",
      "Epoch 216/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0435 - acc: 0.9830 - val_loss: 0.1327 - val_acc: 0.9600\n",
      "Epoch 217/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 0.1394 - val_acc: 0.9600\n",
      "Epoch 218/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0379 - acc: 0.9873 - val_loss: 0.1073 - val_acc: 0.9800\n",
      "Epoch 219/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0359 - acc: 0.9844 - val_loss: 0.0996 - val_acc: 0.9800\n",
      "Epoch 220/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0376 - acc: 0.9929 - val_loss: 0.1171 - val_acc: 0.9800\n",
      "Epoch 221/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0327 - acc: 0.9929 - val_loss: 0.1401 - val_acc: 0.9800\n",
      "Epoch 222/400\n",
      "706/706 [==============================] - 0s 208us/step - loss: 0.0348 - acc: 0.9943 - val_loss: 0.1238 - val_acc: 0.9800\n",
      "Epoch 223/400\n",
      "706/706 [==============================] - 0s 203us/step - loss: 0.0237 - acc: 0.9901 - val_loss: 0.1130 - val_acc: 0.9800\n",
      "Epoch 224/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0538 - acc: 0.9858 - val_loss: 0.1313 - val_acc: 0.9600\n",
      "Epoch 225/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0321 - acc: 0.9915 - val_loss: 0.1475 - val_acc: 0.9600\n",
      "Epoch 226/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0356 - acc: 0.9901 - val_loss: 0.1422 - val_acc: 0.9600\n",
      "Epoch 227/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0254 - acc: 0.9929 - val_loss: 0.1456 - val_acc: 0.9800\n",
      "Epoch 228/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.0327 - acc: 0.9887 - val_loss: 0.1216 - val_acc: 0.9600\n",
      "Epoch 229/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0317 - acc: 0.9915 - val_loss: 0.1137 - val_acc: 0.9600\n",
      "Epoch 230/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0350 - acc: 0.9873 - val_loss: 0.1062 - val_acc: 0.9800\n",
      "Epoch 231/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.0299 - acc: 0.9929 - val_loss: 0.1529 - val_acc: 0.9600\n",
      "Epoch 232/400\n",
      "706/706 [==============================] - 0s 205us/step - loss: 0.0304 - acc: 0.9887 - val_loss: 0.1516 - val_acc: 0.9800\n",
      "Epoch 233/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0384 - acc: 0.9858 - val_loss: 0.1565 - val_acc: 0.9800\n",
      "Epoch 234/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0312 - acc: 0.9915 - val_loss: 0.1437 - val_acc: 0.9800\n",
      "Epoch 235/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 0.1574 - val_acc: 0.9800\n",
      "Epoch 236/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0515 - acc: 0.9873 - val_loss: 0.1545 - val_acc: 0.9800\n",
      "Epoch 237/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.1263 - val_acc: 0.9800\n",
      "Epoch 238/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0445 - acc: 0.9844 - val_loss: 0.1408 - val_acc: 0.9800\n",
      "Epoch 239/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0202 - acc: 0.9943 - val_loss: 0.1202 - val_acc: 0.9800\n",
      "Epoch 240/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0527 - acc: 0.9858 - val_loss: 0.1054 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0519 - acc: 0.9858 - val_loss: 0.1149 - val_acc: 0.9800\n",
      "Epoch 242/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0358 - acc: 0.9816 - val_loss: 0.1318 - val_acc: 0.9600\n",
      "Epoch 243/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0312 - acc: 0.9887 - val_loss: 0.1263 - val_acc: 0.9800\n",
      "Epoch 244/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0311 - acc: 0.9915 - val_loss: 0.1350 - val_acc: 0.9800\n",
      "Epoch 245/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0273 - acc: 0.9887 - val_loss: 0.1211 - val_acc: 0.9800\n",
      "Epoch 246/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0484 - acc: 0.9858 - val_loss: 0.1186 - val_acc: 0.9800\n",
      "Epoch 247/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0363 - acc: 0.9901 - val_loss: 0.1349 - val_acc: 0.9800\n",
      "Epoch 248/400\n",
      "706/706 [==============================] - 0s 174us/step - loss: 0.0349 - acc: 0.9901 - val_loss: 0.1156 - val_acc: 0.9800\n",
      "Epoch 249/400\n",
      "706/706 [==============================] - 0s 216us/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.1420 - val_acc: 0.9800\n",
      "Epoch 250/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0215 - acc: 0.9929 - val_loss: 0.1303 - val_acc: 0.9800\n",
      "Epoch 251/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.1301 - val_acc: 0.9800\n",
      "Epoch 252/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0241 - acc: 0.9915 - val_loss: 0.1322 - val_acc: 0.9800\n",
      "Epoch 253/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0307 - acc: 0.9915 - val_loss: 0.1380 - val_acc: 0.9800\n",
      "Epoch 254/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0486 - acc: 0.9901 - val_loss: 0.1613 - val_acc: 0.9800\n",
      "Epoch 255/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0304 - acc: 0.9887 - val_loss: 0.1463 - val_acc: 0.9800\n",
      "Epoch 256/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0221 - acc: 0.9887 - val_loss: 0.1408 - val_acc: 0.9800\n",
      "Epoch 257/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.1412 - val_acc: 0.9800\n",
      "Epoch 258/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0362 - acc: 0.9915 - val_loss: 0.1701 - val_acc: 0.9800\n",
      "Epoch 259/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0275 - acc: 0.9873 - val_loss: 0.1292 - val_acc: 0.9800\n",
      "Epoch 260/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.1348 - val_acc: 0.9800\n",
      "Epoch 261/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0360 - acc: 0.9901 - val_loss: 0.1224 - val_acc: 0.9800\n",
      "Epoch 262/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 0.0309 - acc: 0.9887 - val_loss: 0.1194 - val_acc: 0.9800\n",
      "Epoch 263/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0445 - acc: 0.9901 - val_loss: 0.1578 - val_acc: 0.9800\n",
      "Epoch 264/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0510 - acc: 0.9858 - val_loss: 0.1788 - val_acc: 0.9600\n",
      "Epoch 265/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0407 - acc: 0.9873 - val_loss: 0.1348 - val_acc: 0.9600\n",
      "Epoch 266/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0340 - acc: 0.9901 - val_loss: 0.1452 - val_acc: 0.9800\n",
      "Epoch 267/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0373 - acc: 0.9901 - val_loss: 0.1321 - val_acc: 0.9800\n",
      "Epoch 268/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0312 - acc: 0.9901 - val_loss: 0.1508 - val_acc: 0.9800\n",
      "Epoch 269/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0236 - acc: 0.9929 - val_loss: 0.1507 - val_acc: 0.9800\n",
      "Epoch 270/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0246 - acc: 0.9915 - val_loss: 0.1317 - val_acc: 0.9800\n",
      "Epoch 271/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0237 - acc: 0.9929 - val_loss: 0.1576 - val_acc: 0.9600\n",
      "Epoch 272/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0184 - acc: 0.9958 - val_loss: 0.1407 - val_acc: 0.9800\n",
      "Epoch 273/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0368 - acc: 0.9858 - val_loss: 0.1693 - val_acc: 0.9800\n",
      "Epoch 274/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0231 - acc: 0.9915 - val_loss: 0.1827 - val_acc: 0.9800\n",
      "Epoch 275/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0413 - acc: 0.9858 - val_loss: 0.1298 - val_acc: 0.9800\n",
      "Epoch 276/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0299 - acc: 0.9929 - val_loss: 0.1597 - val_acc: 0.9800\n",
      "Epoch 277/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0267 - acc: 0.9873 - val_loss: 0.1777 - val_acc: 0.9800\n",
      "Epoch 278/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0155 - acc: 0.9958 - val_loss: 0.1425 - val_acc: 0.9800\n",
      "Epoch 279/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0232 - acc: 0.9943 - val_loss: 0.1566 - val_acc: 0.9800\n",
      "Epoch 280/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0235 - acc: 0.9915 - val_loss: 0.1687 - val_acc: 0.9800\n",
      "Epoch 281/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0475 - acc: 0.9873 - val_loss: 0.1567 - val_acc: 0.9800\n",
      "Epoch 282/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0217 - acc: 0.9929 - val_loss: 0.1537 - val_acc: 0.9600\n",
      "Epoch 283/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0137 - acc: 0.9929 - val_loss: 0.1671 - val_acc: 0.9600\n",
      "Epoch 284/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0293 - acc: 0.9915 - val_loss: 0.1942 - val_acc: 0.9600\n",
      "Epoch 285/400\n",
      "706/706 [==============================] - 0s 170us/step - loss: 0.0171 - acc: 0.9929 - val_loss: 0.2027 - val_acc: 0.9600\n",
      "Epoch 286/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.1886 - val_acc: 0.9600\n",
      "Epoch 287/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0100 - acc: 0.9972 - val_loss: 0.2215 - val_acc: 0.9600\n",
      "Epoch 288/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0293 - acc: 0.9929 - val_loss: 0.1949 - val_acc: 0.9800\n",
      "Epoch 289/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0757 - acc: 0.9830 - val_loss: 0.2089 - val_acc: 0.9600\n",
      "Epoch 290/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0458 - acc: 0.9887 - val_loss: 0.2046 - val_acc: 0.9600\n",
      "Epoch 291/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0224 - acc: 0.9943 - val_loss: 0.1792 - val_acc: 0.9800\n",
      "Epoch 292/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.1681 - val_acc: 0.9600\n",
      "Epoch 293/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0312 - acc: 0.9887 - val_loss: 0.1793 - val_acc: 0.9600\n",
      "Epoch 294/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0244 - acc: 0.9901 - val_loss: 0.1685 - val_acc: 0.9600\n",
      "Epoch 295/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0257 - acc: 0.9915 - val_loss: 0.2047 - val_acc: 0.9600\n",
      "Epoch 296/400\n",
      "706/706 [==============================] - 0s 209us/step - loss: 0.0346 - acc: 0.9887 - val_loss: 0.1870 - val_acc: 0.9800\n",
      "Epoch 297/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0406 - acc: 0.9858 - val_loss: 0.1722 - val_acc: 0.9600\n",
      "Epoch 298/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0443 - acc: 0.9901 - val_loss: 0.1682 - val_acc: 0.9800\n",
      "Epoch 299/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0319 - acc: 0.9873 - val_loss: 0.1606 - val_acc: 0.9800\n",
      "Epoch 300/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0246 - acc: 0.9915 - val_loss: 0.1560 - val_acc: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/400\n",
      "706/706 [==============================] - 0s 210us/step - loss: 0.0178 - acc: 0.9943 - val_loss: 0.1644 - val_acc: 0.9800\n",
      "Epoch 302/400\n",
      "706/706 [==============================] - 0s 239us/step - loss: 0.0131 - acc: 0.9943 - val_loss: 0.1511 - val_acc: 0.9800\n",
      "Epoch 303/400\n",
      "706/706 [==============================] - 0s 237us/step - loss: 0.0273 - acc: 0.9901 - val_loss: 0.1976 - val_acc: 0.9800\n",
      "Epoch 304/400\n",
      "706/706 [==============================] - 0s 218us/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.1526 - val_acc: 0.9800\n",
      "Epoch 305/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0224 - acc: 0.9929 - val_loss: 0.1855 - val_acc: 0.9800\n",
      "Epoch 306/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0209 - acc: 0.9901 - val_loss: 0.1956 - val_acc: 0.9800\n",
      "Epoch 307/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0317 - acc: 0.9887 - val_loss: 0.1978 - val_acc: 0.9800\n",
      "Epoch 308/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0123 - acc: 0.9958 - val_loss: 0.2233 - val_acc: 0.9600\n",
      "Epoch 309/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0220 - acc: 0.9929 - val_loss: 0.2014 - val_acc: 0.9800\n",
      "Epoch 310/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0404 - acc: 0.9873 - val_loss: 0.2113 - val_acc: 0.9800\n",
      "Epoch 311/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.1956 - val_acc: 0.9600\n",
      "Epoch 312/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0245 - acc: 0.9929 - val_loss: 0.1849 - val_acc: 0.9600\n",
      "Epoch 313/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.1897 - val_acc: 0.9800\n",
      "Epoch 314/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0135 - acc: 0.9943 - val_loss: 0.1951 - val_acc: 0.9800\n",
      "Epoch 315/400\n",
      "706/706 [==============================] - 0s 192us/step - loss: 0.0144 - acc: 0.9943 - val_loss: 0.2100 - val_acc: 0.9600\n",
      "Epoch 316/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.2385 - val_acc: 0.9600\n",
      "Epoch 317/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0199 - acc: 0.9929 - val_loss: 0.2211 - val_acc: 0.9600\n",
      "Epoch 318/400\n",
      "706/706 [==============================] - 0s 205us/step - loss: 0.0374 - acc: 0.9844 - val_loss: 0.2161 - val_acc: 0.9600\n",
      "Epoch 319/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0369 - acc: 0.9915 - val_loss: 0.1724 - val_acc: 0.9600\n",
      "Epoch 320/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0431 - acc: 0.9901 - val_loss: 0.1846 - val_acc: 0.9600\n",
      "Epoch 321/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0257 - acc: 0.9915 - val_loss: 0.1922 - val_acc: 0.9600\n",
      "Epoch 322/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0243 - acc: 0.9915 - val_loss: 0.1707 - val_acc: 0.9600\n",
      "Epoch 323/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0251 - acc: 0.9929 - val_loss: 0.2001 - val_acc: 0.9600\n",
      "Epoch 324/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0222 - acc: 0.9915 - val_loss: 0.1920 - val_acc: 0.9600\n",
      "Epoch 325/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0236 - acc: 0.9873 - val_loss: 0.1950 - val_acc: 0.9600\n",
      "Epoch 326/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0282 - acc: 0.9958 - val_loss: 0.2139 - val_acc: 0.9600\n",
      "Epoch 327/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.1979 - val_acc: 0.9800\n",
      "Epoch 328/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0262 - acc: 0.9915 - val_loss: 0.2245 - val_acc: 0.9600\n",
      "Epoch 329/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0128 - acc: 0.9986 - val_loss: 0.2385 - val_acc: 0.9600\n",
      "Epoch 330/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0293 - acc: 0.9901 - val_loss: 0.2508 - val_acc: 0.9600\n",
      "Epoch 331/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0253 - acc: 0.9915 - val_loss: 0.2107 - val_acc: 0.9600\n",
      "Epoch 332/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.2144 - val_acc: 0.9800\n",
      "Epoch 333/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0374 - acc: 0.9901 - val_loss: 0.1786 - val_acc: 0.9800\n",
      "Epoch 334/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0419 - acc: 0.9887 - val_loss: 0.1629 - val_acc: 0.9800\n",
      "Epoch 335/400\n",
      "706/706 [==============================] - 0s 179us/step - loss: 0.0589 - acc: 0.9915 - val_loss: 0.1877 - val_acc: 0.9600\n",
      "Epoch 336/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0284 - acc: 0.9901 - val_loss: 0.1887 - val_acc: 0.9600\n",
      "Epoch 337/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0306 - acc: 0.9901 - val_loss: 0.1900 - val_acc: 0.9600\n",
      "Epoch 338/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0245 - acc: 0.9901 - val_loss: 0.2042 - val_acc: 0.9800\n",
      "Epoch 339/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0226 - acc: 0.9929 - val_loss: 0.1749 - val_acc: 0.9800\n",
      "Epoch 340/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0607 - acc: 0.9858 - val_loss: 0.1693 - val_acc: 0.9800\n",
      "Epoch 341/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0146 - acc: 0.9958 - val_loss: 0.2051 - val_acc: 0.9600\n",
      "Epoch 342/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0213 - acc: 0.9943 - val_loss: 0.2105 - val_acc: 0.9600\n",
      "Epoch 343/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0157 - acc: 0.9972 - val_loss: 0.2270 - val_acc: 0.9600\n",
      "Epoch 344/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0256 - acc: 0.9929 - val_loss: 0.2400 - val_acc: 0.9600\n",
      "Epoch 345/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0180 - acc: 0.9943 - val_loss: 0.2485 - val_acc: 0.9600\n",
      "Epoch 346/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0164 - acc: 0.9929 - val_loss: 0.2041 - val_acc: 0.9600\n",
      "Epoch 347/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0286 - acc: 0.9943 - val_loss: 0.2972 - val_acc: 0.9600\n",
      "Epoch 348/400\n",
      "706/706 [==============================] - 0s 181us/step - loss: 0.0176 - acc: 0.9958 - val_loss: 0.3033 - val_acc: 0.9600\n",
      "Epoch 349/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0256 - acc: 0.9901 - val_loss: 0.2810 - val_acc: 0.9600\n",
      "Epoch 350/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0263 - acc: 0.9887 - val_loss: 0.2425 - val_acc: 0.9600\n",
      "Epoch 351/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0157 - acc: 0.9943 - val_loss: 0.2702 - val_acc: 0.9600\n",
      "Epoch 352/400\n",
      "706/706 [==============================] - 0s 203us/step - loss: 0.0202 - acc: 0.9901 - val_loss: 0.2256 - val_acc: 0.9600\n",
      "Epoch 353/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0250 - acc: 0.9929 - val_loss: 0.2114 - val_acc: 0.9600\n",
      "Epoch 354/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0180 - acc: 0.9958 - val_loss: 0.2300 - val_acc: 0.9600\n",
      "Epoch 355/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0196 - acc: 0.9929 - val_loss: 0.2182 - val_acc: 0.9600\n",
      "Epoch 356/400\n",
      "706/706 [==============================] - 0s 199us/step - loss: 0.0312 - acc: 0.9929 - val_loss: 0.2067 - val_acc: 0.9600\n",
      "Epoch 357/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0383 - acc: 0.9943 - val_loss: 0.2073 - val_acc: 0.9600\n",
      "Epoch 358/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0169 - acc: 0.9943 - val_loss: 0.2191 - val_acc: 0.9600\n",
      "Epoch 359/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0285 - acc: 0.9958 - val_loss: 0.2048 - val_acc: 0.9600\n",
      "Epoch 360/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0201 - acc: 0.9901 - val_loss: 0.1715 - val_acc: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.0267 - acc: 0.9901 - val_loss: 0.2208 - val_acc: 0.9600\n",
      "Epoch 362/400\n",
      "706/706 [==============================] - 0s 170us/step - loss: 0.0277 - acc: 0.9887 - val_loss: 0.1930 - val_acc: 0.9800\n",
      "Epoch 363/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 0.0252 - acc: 0.9929 - val_loss: 0.2390 - val_acc: 0.9600\n",
      "Epoch 364/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0240 - acc: 0.9958 - val_loss: 0.2524 - val_acc: 0.9600\n",
      "Epoch 365/400\n",
      "706/706 [==============================] - 0s 177us/step - loss: 0.0202 - acc: 0.9915 - val_loss: 0.2651 - val_acc: 0.9600\n",
      "Epoch 366/400\n",
      "706/706 [==============================] - 0s 201us/step - loss: 0.0206 - acc: 0.9915 - val_loss: 0.2610 - val_acc: 0.9600\n",
      "Epoch 367/400\n",
      "706/706 [==============================] - 0s 182us/step - loss: 0.0278 - acc: 0.9929 - val_loss: 0.2354 - val_acc: 0.9800\n",
      "Epoch 368/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0182 - acc: 0.9915 - val_loss: 0.2649 - val_acc: 0.9800\n",
      "Epoch 369/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.2665 - val_acc: 0.9600\n",
      "Epoch 370/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0125 - acc: 0.9943 - val_loss: 0.2439 - val_acc: 0.9800\n",
      "Epoch 371/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0262 - acc: 0.9943 - val_loss: 0.2947 - val_acc: 0.9600\n",
      "Epoch 372/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0103 - acc: 0.9958 - val_loss: 0.2896 - val_acc: 0.9600\n",
      "Epoch 373/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0200 - acc: 0.9958 - val_loss: 0.2458 - val_acc: 0.9600\n",
      "Epoch 374/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0229 - acc: 0.9929 - val_loss: 0.2311 - val_acc: 0.9600\n",
      "Epoch 375/400\n",
      "706/706 [==============================] - 0s 210us/step - loss: 0.0247 - acc: 0.9929 - val_loss: 0.2637 - val_acc: 0.9600\n",
      "Epoch 376/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0303 - acc: 0.9943 - val_loss: 0.2329 - val_acc: 0.9600\n",
      "Epoch 377/400\n",
      "706/706 [==============================] - 0s 202us/step - loss: 0.0229 - acc: 0.9943 - val_loss: 0.3152 - val_acc: 0.9600\n",
      "Epoch 378/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0264 - acc: 0.9915 - val_loss: 0.2487 - val_acc: 0.9600\n",
      "Epoch 379/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0238 - acc: 0.9929 - val_loss: 0.2104 - val_acc: 0.9600\n",
      "Epoch 380/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0307 - acc: 0.9929 - val_loss: 0.1807 - val_acc: 0.9800\n",
      "Epoch 381/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0360 - acc: 0.9887 - val_loss: 0.2063 - val_acc: 0.9600\n",
      "Epoch 382/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0149 - acc: 0.9972 - val_loss: 0.2208 - val_acc: 0.9600\n",
      "Epoch 383/400\n",
      "706/706 [==============================] - 0s 170us/step - loss: 0.0109 - acc: 0.9958 - val_loss: 0.2235 - val_acc: 0.9600\n",
      "Epoch 384/400\n",
      "706/706 [==============================] - 0s 188us/step - loss: 0.0431 - acc: 0.9901 - val_loss: 0.2141 - val_acc: 0.9600\n",
      "Epoch 385/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0187 - acc: 0.9958 - val_loss: 0.2149 - val_acc: 0.9600\n",
      "Epoch 386/400\n",
      "706/706 [==============================] - 0s 196us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.2759 - val_acc: 0.9600\n",
      "Epoch 387/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0139 - acc: 0.9958 - val_loss: 0.2556 - val_acc: 0.9600\n",
      "Epoch 388/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.2400 - val_acc: 0.9600\n",
      "Epoch 389/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0246 - acc: 0.9915 - val_loss: 0.2106 - val_acc: 0.9600\n",
      "Epoch 390/400\n",
      "706/706 [==============================] - 0s 185us/step - loss: 0.0174 - acc: 0.9915 - val_loss: 0.2096 - val_acc: 0.9600\n",
      "Epoch 391/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0221 - acc: 0.9929 - val_loss: 0.2109 - val_acc: 0.9600\n",
      "Epoch 392/400\n",
      "706/706 [==============================] - 0s 178us/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.2402 - val_acc: 0.9600\n",
      "Epoch 393/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0635 - acc: 0.9858 - val_loss: 0.2422 - val_acc: 0.9600\n",
      "Epoch 394/400\n",
      "706/706 [==============================] - 0s 186us/step - loss: 0.0123 - acc: 0.9943 - val_loss: 0.2309 - val_acc: 0.9600\n",
      "Epoch 395/400\n",
      "706/706 [==============================] - 0s 195us/step - loss: 0.0318 - acc: 0.9901 - val_loss: 0.1929 - val_acc: 0.9600\n",
      "Epoch 396/400\n",
      "706/706 [==============================] - 0s 184us/step - loss: 0.0124 - acc: 0.9943 - val_loss: 0.1768 - val_acc: 0.9800\n",
      "Epoch 397/400\n",
      "706/706 [==============================] - 0s 194us/step - loss: 0.0351 - acc: 0.9915 - val_loss: 0.1834 - val_acc: 0.9800\n",
      "Epoch 398/400\n",
      "706/706 [==============================] - 0s 191us/step - loss: 0.0262 - acc: 0.9901 - val_loss: 0.1859 - val_acc: 0.9800\n",
      "Epoch 399/400\n",
      "706/706 [==============================] - 0s 189us/step - loss: 0.0310 - acc: 0.9844 - val_loss: 0.1872 - val_acc: 0.9800\n",
      "Epoch 400/400\n",
      "706/706 [==============================] - 0s 198us/step - loss: 0.0138 - acc: 0.9943 - val_loss: 0.1916 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(input_train,y_train,batch_size=10,epochs=400,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/datasetx_train3.json\")\n",
    "obj_r2 = open(\"./test/json/datasetx_result3.json\")\n",
    "test = json.load(obj_r)\n",
    "test = np.array(test)\n",
    "t = json.load(obj_r2)\n",
    "print(len(test))\n",
    "t = np.array(t)\n",
    "t = t*2093.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1.0, 1.0, 0.9999957, 1.0, 1.0, 0.9999989, 0.99999964, 1.0, 1.0, 1.0, 0.99971694, 1.0, 1.0, 0.9951774, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99999964, 0.99999976, 0.9854666, 0.9999964, 0.99999905, 0.9998733, 1.0, 1.0, 0.99999595, 1.0, 0.9999999, 0.9999956, 0.9998703, 1.0, 1.0, 0.99999547, 0.99999845, 0.99999714, 0.99999976, 0.9996481, 0.9993395, 0.9988318, 1.0, 1.0, 1.0, 1.0, 0.9999993, 1.0, 0.9999993, 0.9999999, 1.0, 0.99995255, 1.0, 0.9999933, 0.9995326, 0.99999523, 0.9895466, 1.0, 0.999567, 0.9998865, 0.9999999, 1.0, 1.0, 1.0, 0.8732059, 0.9990627, 1.0, 0.99976486, 0.99999535, 1.0, 0.98594266, 0.99999964, 1.0, 1.0, 1.0, 0.9928784, 0.99999833, 1.0, 0.7250211, 1.0, 1.0, 0.99999976, 0.9999945, 1.0, 0.9634863, 1.0, 0.99999833, 0.9999994, 0.99999654, 1.0, 0.99999964, 1.0, 0.9999995, 1.0, 0.9999745, 1.0, 0.99974245, 0.99997437, 0.99977523, 0.99999964, 1.0, 0.9999999, 1.0, 0.99999857, 1.0, 0.99989855, 0.99999964, 1.0, 0.9999995, 0.99997723, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.992531, 0.9999958, 1.0, 0.99986744, 1.0, 0.9999975, 0.9999949, 0.9443388, 1.0, 1.0, 0.99998343, 0.9999547, 1.0, 0.9996792, 1.0, 0.99986637, 0.9999745, 0.8804959, 0.9999999, 1.0, 1.0, 0.9999951, 1.0, 1.0, 0.99999857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999523, 1.0, 0.9999995, 1.0, 1.0, 0.9999907, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.997687, 1.0, 0.99999976, 0.99999964, 0.99999976, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9999999, 1.0, 0.9999982, 1.0, 0.9999987, 0.999998, 0.99999976, 0.9981865, 1.0, 1.0, 0.99986076, 1.0, 0.9999405, 1.0, 0.99999976, 0.99624807, 0.99999726, 0.99999976, 1.0, 1.0, 1.0, 0.99999905, 1.0, 0.99999654, 1.0, 0.9999999, 1.0, 1.0, 0.9999956, 1.0, 0.9999771, 0.9997445, 1.0, 1.0, 0.99999976, 0.99994314, 0.9999889, 1.0, 1.0, 1.0, 0.99999905, 0.9987237, 0.99521196, 1.0, 0.9455078, 1.0, 1.0, 1.0, 0.9999999, 1.0, 1.0, 0.99997425, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99999833, 1.0, 1.0, 0.9999969, 1.0, 0.99999106, 1.0, 1.0, 1.0, 0.9999989, 0.99999976, 1.0, 0.99999976, 1.0, 1.0, 0.9999999, 0.99989486, 0.99999976, 0.99999845, 1.0, 0.9996822, 1.0]\n",
      "1 121\n",
      "0.9895466\n",
      "0.9998865\n",
      "0.8732059\n",
      "0.9634863\n",
      "0.9999999\n",
      "0.9996792\n",
      "0.8804959\n",
      "0.99624807\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " 255  8\n",
      " 0.9686274509803922\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(t)):\n",
    "    index = fre_to_note_piano(t[j])\n",
    "    test_standard.append(index)\n",
    "    \n",
    "\n",
    "predict = model.predict(test)\n",
    "predict_note = []\n",
    "predict_proba = []\n",
    "preict_not_1 = 0\n",
    "for i in range(len(predict)):\n",
    "    index = np.argmax(predict[i])\n",
    "    predict_proba.append(predict[i][index]) \n",
    "    if predict[i][index] != 1:\n",
    "        preict_not_1 += 1\n",
    "    predict_note.append(index+40)\n",
    "print(\"\",predict_proba)\n",
    "print(\"1\",preict_not_1)\n",
    "num = 0\n",
    "wrong_num = 0\n",
    "for i in range(len(predict_note)):\n",
    "    if abs(predict_note[i] - test_standard[i])==0:\n",
    "        num += 1\n",
    "    else:\n",
    "        wrong_num += 1\n",
    "accuracy = num/len(predict_note)\n",
    "# print(predict_note)\n",
    "# print(test_standard)\n",
    "dis = []\n",
    "wrong_poi = []\n",
    "for i in range(len(predict_note)):\n",
    "    dis.append(abs(predict_note[i] - test_standard[i]))\n",
    "    if abs(predict_note[i] - test_standard[i]) != 0:\n",
    "        wrong_poi.append(i)\n",
    "for i in wrong_poi:\n",
    "    print(predict_proba[i])\n",
    "print(dis)\n",
    "print(\"\",len(predict_note),\"\",wrong_num)\n",
    "print(\"\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\n5ywRGGOMz1kiMMYYn/t/RWq7ScXGM6YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "print(history_dict.keys())\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17.]\n",
      " [20.]\n",
      " [14.]\n",
      " [18.]\n",
      " [18.]\n",
      " [19.]\n",
      " [14.]\n",
      " [22.]\n",
      " [17.]\n",
      " [15.]\n",
      " [17.]\n",
      " [12.]\n",
      " [15.]\n",
      " [16.]\n",
      " [14.]\n",
      " [19.]\n",
      " [17.]\n",
      " [15.]\n",
      " [21.]\n",
      " [20.]\n",
      " [16.]\n",
      " [15.]\n",
      " [17.]\n",
      " [15.]\n",
      " [18.]\n",
      " [18.]\n",
      " [17.]\n",
      " [15.]\n",
      " [14.]\n",
      " [18.]\n",
      " [17.]\n",
      " [12.]\n",
      " [17.]\n",
      " [17.]\n",
      " [16.]\n",
      " [19.]\n",
      " [17.]\n",
      " [12.]\n",
      " [22.]\n",
      " [21.]\n",
      " [15.]\n",
      " [18.]\n",
      " [19.]\n",
      " [16.]\n",
      " [15.]]\n"
     ]
    }
   ],
   "source": [
    "guitar_data=[]\n",
    "obj_r=open(\"./test/json/examples2.json\")\n",
    "data=json.load(obj_r)\n",
    "note_set = np.zeros((45,1))\n",
    "for file_data in data.items():\n",
    "    if file_data[1]['instrument_family']==3 and file_data[1][\"instrument_source_str\"]==\"acoustic\":\n",
    "        if 40<=file_data[1]['pitch']<=84:\n",
    "            guitar_data.append([file_data[1]['note_str'],file_data[1]['pitch']])\n",
    "            note_set[file_data[1]['pitch']-40] += 1\n",
    "print(note_set)\n",
    "# for i in wrong_poi:\n",
    "#     print(guitar_data[i][0])\n",
    "\n",
    "# for i in wrong_poi:\n",
    "#     print(guitar_data[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
