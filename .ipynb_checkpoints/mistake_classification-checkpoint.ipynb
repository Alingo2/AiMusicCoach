{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(800,)))\n",
    "model.add(layers.Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/wrong_train.json\")\n",
    "obj_r2 = open(\"./test/json/wrong_train_type.json\")\n",
    "input_train = json.load(obj_r)\n",
    "input_train = np.array(input_train)\n",
    "print(len(input_train))\n",
    "y = json.load(obj_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.zeros((len(y),5))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    index = y[i]\n",
    "    y_train[i] = 1\n",
    "    \n",
    "x_val=input_train[0:20]\n",
    "y_val=y_train[0:20]\n",
    "input_train=input_train[20:]\n",
    "y_train=y_train[20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60 samples, validate on 20 samples\n",
      "Epoch 1/400\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 8.0490 - acc: 0.2500 - val_loss: 8.0479 - val_acc: 0.2000\n",
      "Epoch 2/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0474 - acc: 0.2333 - val_loss: 8.0477 - val_acc: 0.1000\n",
      "Epoch 3/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0473 - acc: 0.1667 - val_loss: 8.0475 - val_acc: 0.1000\n",
      "Epoch 4/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0473 - acc: 0.2500 - val_loss: 8.0474 - val_acc: 0.2500\n",
      "Epoch 5/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0473 - acc: 0.2500 - val_loss: 8.0475 - val_acc: 0.0000e+00\n",
      "Epoch 6/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0473 - acc: 0.1667 - val_loss: 8.0473 - val_acc: 0.2500\n",
      "Epoch 7/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2000 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 8/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2167 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 9/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1000 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 10/400\n",
      "60/60 [==============================] - 0s 581us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 11/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2167 - val_loss: 8.0472 - val_acc: 0.3500\n",
      "Epoch 12/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.3167 - val_loss: 8.0472 - val_acc: 0.1500\n",
      "Epoch 13/400\n",
      "60/60 [==============================] - 0s 516us/step - loss: 8.0472 - acc: 0.4000 - val_loss: 8.0472 - val_acc: 0.8500\n",
      "Epoch 14/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2167 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 15/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.3667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 16/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.3167 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 17/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 18/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 19/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.6500\n",
      "Epoch 20/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.3167 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 21/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 22/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 23/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 24/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 25/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 26/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 27/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 28/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1833 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 29/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.3167 - val_loss: 8.0472 - val_acc: 0.7000\n",
      "Epoch 30/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 31/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 32/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 33/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 34/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7000\n",
      "Epoch 35/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 36/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 37/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 38/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 39/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 40/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 41/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 42/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 43/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 44/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 45/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 46/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 47/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 48/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 49/400\n",
      "60/60 [==============================] - 0s 332us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 50/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 51/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 52/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 53/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 54/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 55/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 56/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 57/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 58/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 59/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 60/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 61/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 62/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 63/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 64/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 65/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 66/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 67/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 68/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 69/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 70/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 71/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 72/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 73/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 74/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 75/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 76/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.7000\n",
      "Epoch 77/400\n",
      "60/60 [==============================] - 0s 798us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 78/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 79/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 80/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 81/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 82/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 83/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 84/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 85/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 86/400\n",
      "60/60 [==============================] - 0s 531us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 87/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 88/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 89/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 90/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 91/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 92/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 93/400\n",
      "60/60 [==============================] - 0s 466us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 94/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 95/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 96/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 97/400\n",
      "60/60 [==============================] - 0s 631us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 98/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 99/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 100/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7000\n",
      "Epoch 101/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 102/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 103/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 104/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 105/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 106/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 107/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 108/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.7500\n",
      "Epoch 109/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 110/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 111/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 112/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 113/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 114/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 115/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 116/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 117/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 118/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 119/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 120/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 121/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 123/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.7000\n",
      "Epoch 124/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 125/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 126/400\n",
      "60/60 [==============================] - 0s 382us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 127/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 128/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 129/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 130/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 131/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 132/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 133/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.8000\n",
      "Epoch 134/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 135/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 136/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 137/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 138/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.1000\n",
      "Epoch 139/400\n",
      "60/60 [==============================] - 0s 814us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 140/400\n",
      "60/60 [==============================] - 0s 848us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 141/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 142/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 143/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 144/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 145/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 146/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 147/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 148/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 149/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 150/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 151/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 152/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 153/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 154/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 155/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 156/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 157/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 158/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 159/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 160/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 161/400\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.0472 - acc: 0.0000e+0 - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 162/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 163/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 164/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 165/400\n",
      "60/60 [==============================] - 0s 466us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 166/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 167/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 168/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 169/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 170/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 171/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 172/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 173/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 174/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 175/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 176/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 177/400\n",
      "60/60 [==============================] - 0s 581us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 178/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 179/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 180/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 181/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 183/400\n",
      "60/60 [==============================] - 0s 599us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 184/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 185/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 186/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 187/400\n",
      "60/60 [==============================] - 0s 814us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 188/400\n",
      "60/60 [==============================] - 0s 732us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 189/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 190/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 191/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 192/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 193/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 194/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 195/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 196/400\n",
      "60/60 [==============================] - 0s 931us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 197/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 198/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 199/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 200/400\n",
      "60/60 [==============================] - 0s 814us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 201/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 202/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 203/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 204/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 205/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 206/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 207/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 208/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 209/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 210/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 211/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 212/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 213/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 214/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 215/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 216/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 217/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 218/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 219/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 220/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 221/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 222/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 223/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 224/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 225/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 226/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 227/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 228/400\n",
      "60/60 [==============================] - 0s 616us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 229/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 230/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 231/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 232/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 233/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 234/400\n",
      "60/60 [==============================] - 0s 382us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 235/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 236/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 237/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 238/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 239/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 240/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 241/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 242/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 243/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 244/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 245/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 246/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 247/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 248/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 249/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 250/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 251/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 252/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 253/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 254/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 255/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 256/400\n",
      "60/60 [==============================] - 0s 798us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 257/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 258/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 259/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 260/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 261/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 262/400\n",
      "60/60 [==============================] - 0s 781us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 263/400\n",
      "60/60 [==============================] - 0s 814us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 264/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 265/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 266/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 267/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 268/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 269/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 270/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 271/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 272/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 273/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 274/400\n",
      "60/60 [==============================] - 0s 732us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 275/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 276/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 277/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 278/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 279/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 280/400\n",
      "60/60 [==============================] - 0s 765us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 281/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 282/400\n",
      "60/60 [==============================] - 0s 748us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 283/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 284/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 285/400\n",
      "60/60 [==============================] - 0s 781us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 286/400\n",
      "60/60 [==============================] - 0s 898us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 287/400\n",
      "60/60 [==============================] - 0s 847us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 288/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 289/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 290/400\n",
      "60/60 [==============================] - 0s 831us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 291/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 292/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 293/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 294/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 295/400\n",
      "60/60 [==============================] - 0s 814us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 296/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 297/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 298/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 299/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 300/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 301/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 303/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 304/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 305/400\n",
      "60/60 [==============================] - 0s 399us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 306/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 307/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 308/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 309/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 310/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 311/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 312/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 313/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 314/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 315/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 316/400\n",
      "60/60 [==============================] - 0s 498us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 317/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 318/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 319/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 320/400\n",
      "60/60 [==============================] - 0s 631us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 321/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 322/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 323/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 324/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 325/400\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.0472 - acc: 0.0000e+0 - 0s 582us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 326/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 327/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 328/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 329/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 330/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 331/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 332/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 333/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 334/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 335/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 336/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 337/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 338/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 339/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 340/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 341/400\n",
      "60/60 [==============================] - 0s 781us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 342/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 343/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 344/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 345/400\n",
      "60/60 [==============================] - 0s 981us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 346/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 347/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 348/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 349/400\n",
      "60/60 [==============================] - 0s 715us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 350/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 351/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 352/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 353/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 354/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 355/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 356/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 357/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 358/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 359/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 360/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 361/400\n",
      "60/60 [==============================] - 0s 765us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 362/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 363/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 364/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 365/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 366/400\n",
      "60/60 [==============================] - 0s 548us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 367/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 368/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 369/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 370/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 371/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.5000 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 372/400\n",
      "60/60 [==============================] - 0s 499us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 373/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 374/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 375/400\n",
      "60/60 [==============================] - 0s 482us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 376/400\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 377/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 378/400\n",
      "60/60 [==============================] - 0s 416us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 379/400\n",
      "60/60 [==============================] - 0s 632us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 380/400\n",
      "60/60 [==============================] - 0s 682us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 381/400\n",
      "60/60 [==============================] - 0s 432us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 382/400\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 383/400\n",
      "60/60 [==============================] - 0s 615us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 384/400\n",
      "60/60 [==============================] - 0s 449us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 385/400\n",
      "60/60 [==============================] - 0s 648us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 386/400\n",
      "60/60 [==============================] - 0s 415us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 387/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 388/400\n",
      "60/60 [==============================] - 0s 665us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 389/400\n",
      "60/60 [==============================] - 0s 515us/step - loss: 8.0472 - acc: 0.4167 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 390/400\n",
      "60/60 [==============================] - 0s 465us/step - loss: 8.0472 - acc: 0.0000e+00 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 391/400\n",
      "60/60 [==============================] - 0s 781us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 392/400\n",
      "60/60 [==============================] - 0s 532us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 393/400\n",
      "60/60 [==============================] - 0s 582us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 394/400\n",
      "60/60 [==============================] - 0s 598us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 395/400\n",
      "60/60 [==============================] - ETA: 0s - loss: 8.0472 - acc: 0.0000e+0 - 0s 648us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 396/400\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.0472 - acc: 0.2500 - val_loss: 8.0472 - val_acc: 0.0000e+00\n",
      "Epoch 397/400\n",
      "60/60 [==============================] - 0s 565us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 398/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.1667 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 399/400\n",
      "60/60 [==============================] - 0s 765us/step - loss: 8.0472 - acc: 0.3333 - val_loss: 8.0472 - val_acc: 0.0500\n",
      "Epoch 400/400\n",
      "60/60 [==============================] - 0s 549us/step - loss: 8.0472 - acc: 0.0833 - val_loss: 8.0472 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(input_train,y_train,batch_size=5,epochs=400,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "obj_r=open(\"./test/json/wrong_test.json\")\n",
    "obj_r2 = open(\"./test/json/wrong_test_type.json\")\n",
    "\n",
    "\n",
    "test = json.load(obj_r)\n",
    "test = np.array(test)\n",
    "t = json.load(obj_r2)\n",
    "print(len(test))\n",
    "t = np.array(t)\n",
    "test_standard = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009744, 0.20009808, 0.20009744, 0.20013127, 0.20017548, 0.20009744, 0.20055917, 0.20009744, 0.20009744, 0.20009744]\n",
      "1 0\n",
      " 20  15\n",
      " 0.25\n"
     ]
    }
   ],
   "source": [
    "wrongfile_list=[]\n",
    "predict = model.predict(test)\n",
    "predict_type = []\n",
    "predict_proba = []\n",
    "preict_not_1 = 0\n",
    "for i in range(len(predict)):\n",
    "    index = np.argmax(predict[i])\n",
    "    predict_proba.append(predict[i][index]) \n",
    "    predict_type.append(index)\n",
    "\n",
    "print(\"\",predict_proba)\n",
    "print(\"1\",preict_not_1)\n",
    "num = 0\n",
    "wrong_num = 0\n",
    "for i in range(len(predict_type)):\n",
    "    if abs(predict_type[i] - test_standard[i])==0:\n",
    "        num += 1\n",
    "    else:\n",
    "        wrong_num += 1\n",
    "accuracy = num/len(predict_type)\n",
    "# print(predict_note)\n",
    "# print(test_standard)\n",
    "print(\"\",len(predict_type),\"\",wrong_num)\n",
    "print(\"\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "print(history_dict.keys())\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
